{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch lightning torchvision av","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resnet 3D","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport math\nfrom functools import partial\n\n\ndef conv3x3x3(in_planes, out_planes, stride=1):\n    # 3x3x3 convolution with padding\n    return nn.Conv3d(\n        in_planes,\n        out_planes,\n        kernel_size=3,\n        stride=stride,\n        padding=1,\n        bias=False)\n\n\ndef downsample_basic_block(x, planes, stride):\n    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n    zero_pads = torch.Tensor(\n        out.size(0), \n        planes - out.size(1), \n        out.size(2), \n        out.size(3),\n        out.size(4)\n    ).zero_()\n    \n    if isinstance(out.data, torch.cuda.FloatTensor):\n        zero_pads = zero_pads.cuda()\n\n    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n\n    return out\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3x3(planes, planes)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm3d(planes)\n\n        self.conv2 = nn.Conv3d(\n            planes, planes, \n            kernel_size=3, stride=stride, padding=1, \n            bias=False)\n        self.bn2 = nn.BatchNorm3d(planes)\n        \n        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm3d(planes * 4)\n        \n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self,\n                 block,\n                 layers,\n                 sample_size,\n                 sample_duration,\n                 shortcut_type='B',\n                 num_classes=400):\n        \n        \"\"\"\n        block: basic block or bottle neck\n        layers: define Resnet architecture 34, 101, 152 etc\n        sample size: image size\n        shortcut_type: 'A' or 'B'\n        num_classes: ...\n        \"\"\"\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv3d(\n            3,\n            64,\n            kernel_size=7,\n            stride=(1, 2, 2),\n            padding=(3, 3, 3),\n            bias=False)\n        self.bn1 = nn.BatchNorm3d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n\n\n        self.layer1 = self._make_layer(\n            block, 64, layers[0], shortcut_type)\n        self.layer2 = self._make_layer(\n            block, 128, layers[1], shortcut_type, stride=2)\n        self.layer3 = self._make_layer(\n            block, 256, layers[2], shortcut_type, stride=2)\n        self.layer4 = self._make_layer(\n            block, 512, layers[3], shortcut_type, stride=2)\n        \n        \n        last_duration = int(math.ceil(sample_duration / 16))\n        last_size = int(math.ceil(sample_size / 32))\n        self.avgpool = nn.AvgPool3d(\n            (last_duration, last_size, last_size), stride=1)\n        \n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n            elif isinstance(m, nn.BatchNorm3d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            if shortcut_type == 'A':\n                downsample = partial(\n                    downsample_basic_block,\n                    planes=planes * block.expansion,\n                    stride=stride)\n            else:\n                downsample = nn.Sequential(\n                    nn.Conv3d(\n                        self.inplanes,\n                        planes * block.expansion,\n                        kernel_size=1,\n                        stride=stride,\n                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef get_fine_tuning_parameters(model, ft_portion):\n    if ft_portion == \"complete\":\n        return model.parameters()\n\n    elif ft_portion == \"last_layer\":\n        ft_module_names = []\n        ft_module_names.append('classifier')\n\n        parameters = []\n        for k, v in model.named_parameters():\n            for ft_module in ft_module_names:\n                if ft_module in k:\n                    parameters.append({'params': v})\n                    break\n            else:\n                parameters.append({'params': v, 'lr': 0.0})\n        return parameters\n\n    else:\n        raise ValueError(\"Unsupported ft_portion: 'complete' or 'last_layer' expected\")\n\n\ndef resnet10(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n    return model\n\n\ndef resnet18(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    return model\n\n\ndef resnet34(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    return model\n\n\ndef resnet50(**kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    return model\n\n\ndef resnet101(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    return model\n\n\ndef resnet152(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    return model\n\n\ndef resnet200(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T00:49:55.133768Z","iopub.execute_input":"2024-06-25T00:49:55.134139Z","iopub.status.idle":"2024-06-25T00:49:57.120516Z","shell.execute_reply.started":"2024-06-25T00:49:55.134109Z","shell.execute_reply":"2024-06-25T00:49:57.119255Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pathlib\nimport torch\n# from GesRec.models.resnet import resnet101\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.io import read_video\nimport lightning as L\nfrom lightning.pytorch.loggers import CSVLogger\n\nbatch_size = 8\n\nclass KeyClf(L.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = resnet101(sample_size=224,\n                 sample_duration=16,\n                 shortcut_type='A',\n                 num_classes=30)\n        \n        self.loss_fn = torch.nn.CrossEntropyLoss()\n\n    def training_step(self, batch):\n        videos, targets = batch\n        outputs = self.model(videos)\n        loss = self.loss_fn(outputs, targets.long())\n\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.model.parameters(), lr=0.01)\n    \nclass KeyStrokeClsDataset(Dataset):\n    def __init__(self, dataset_root_path, mode):\n        self.dataset_root_path = pathlib.Path(dataset_root_path)\n        self.all_video_file_paths =  list(self.dataset_root_path.glob(f\"{mode}/*/*.mp4\"))\n        self.class_labels = sorted({str(path).split(\"/\")[-2] for path in self.all_video_file_paths})\n        self.label2id = {label: i for i, label in enumerate(self.class_labels)}\n        self.id2label  = {i: label for label, i in self.label2id.items()}\n\n    def __len__(self):\n        return len(self.all_video_file_paths)\n\n    def __getitem__(self, idx):\n        file_path = self.all_video_file_paths[idx]\n        vframes, _, _ = read_video(file_path, pts_unit='sec')\n        label = str(file_path).split(\"/\")[-2]\n\n        # permute to (num_frames, num_channels, height, width)\n        vframes = vframes.permute(3, 0, 1, 2).float() / 255.0\n    \n        return vframes, self.label2id[label]\n\n\nclass KeyClsData(L.LightningDataModule):\n    def train_dataloader(self):\n        train_dataset = KeyStrokeClsDataset(\"/kaggle/input/keystroker-classify/keystroke_classify_data\", 'train')\n        print(\"Train dataset:\", len(train_dataset))\n        return DataLoader(train_dataset, batch_size=batch_size, num_workers=2, persistent_workers=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T00:50:06.263099Z","iopub.execute_input":"2024-06-25T00:50:06.263645Z","iopub.status.idle":"2024-06-25T00:50:06.284193Z","shell.execute_reply.started":"2024-06-25T00:50:06.263599Z","shell.execute_reply":"2024-06-25T00:50:06.282890Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"max_epochs = 10\nmodel = KeyClf()\ndata = KeyClsData()\n# logger = CSVLogger(\"logs\", name=f\"clf_train_batch_{batch_size}_max_epochs_{max_epochs}\")\ntrainer = L.Trainer(max_epochs=max_epochs, devices=[0,1])\ntrainer.fit(model, data)\ntrainer.save_checkpoint(f'./clf_train_batch_{batch_size}_max_epochs_{max_epochs}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TEST**","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\ntest_dataset = KeyStrokeClsDataset(\"/kaggle/input/keystroker-classify/keystroke_classify_data\", 'test')\n\nid2Label = ['BackSpace', 'Comma', 'Space', 'Stop', \n            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', \n            'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', \n            'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n            'y', 'z']\n\nmodel = KeyClf.load_from_checkpoint('/kaggle/working/clf_train_batch_8_max_epochs_10')\nmodel.eval()\ny = []\npredictions = []\nwith torch.no_grad():\n    for video, label in tqdm(test_dataset):\n        logits = model.model(video.unsqueeze(0))\n        y_pred = id2Label[torch.argmax(logits, dim=1).item()]\n        predictions.append(y_pred)\n        y.append(id2Label[label])\n        # print(f\"y_pred: {y_pred}; y: {id2Label[label]}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-25T00:51:36.993757Z","iopub.execute_input":"2024-06-25T00:51:36.994176Z","iopub.status.idle":"2024-06-25T02:23:30.864032Z","shell.execute_reply.started":"2024-06-25T00:51:36.994142Z","shell.execute_reply":"2024-06-25T02:23:30.862875Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_91/1183826950.py:164: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n100%|██████████| 4625/4625 [1:31:51<00:00,  1.19s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y, predictions))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T02:23:31.171390Z","iopub.execute_input":"2024-06-25T02:23:31.171772Z","iopub.status.idle":"2024-06-25T02:23:31.908388Z","shell.execute_reply.started":"2024-06-25T02:23:31.171736Z","shell.execute_reply":"2024-06-25T02:23:31.906717Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n   BackSpace       0.98      0.42      0.58       438\n       Comma       0.25      0.03      0.06        29\n       Space       0.44      0.79      0.57       745\n        Stop       0.20      0.10      0.13        40\n           a       0.60      0.38      0.46       280\n           b       0.62      0.38      0.47        60\n           c       0.79      0.28      0.42        81\n           d       0.76      0.49      0.60       140\n           e       0.88      0.45      0.60       440\n           f       0.96      0.42      0.59        64\n           g       0.15      0.59      0.24        56\n           h       0.47      0.58      0.52       159\n           i       0.69      0.45      0.55       244\n           j       0.00      0.00      0.00         9\n           k       0.19      0.14      0.16        35\n           l       0.70      0.21      0.32       147\n           m       0.59      0.19      0.29        84\n           n       0.95      0.16      0.27       220\n           o       0.62      0.72      0.67       240\n           p       0.28      0.87      0.42        75\n           q       0.00      0.00      0.00         6\n           r       0.81      0.79      0.80       201\n           s       0.79      0.40      0.53       203\n           t       0.64      0.49      0.55       335\n           u       0.08      0.60      0.14        90\n           v       1.00      0.09      0.16        46\n           w       0.34      0.16      0.22        70\n           x       0.50      0.25      0.33         4\n           y       0.75      0.04      0.07        83\n           z       0.00      0.00      0.00         1\n\n    accuracy                           0.49      4625\n   macro avg       0.53      0.35      0.36      4625\nweighted avg       0.66      0.49      0.50      4625\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}