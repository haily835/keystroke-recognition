{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://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@github.com/haily835/Keystroke-classifier.git\n",
    "%cd Keystroke-classifier\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.get_ckpt_path import get_ckpt_path\n",
    "\n",
    "is_available = torch.cuda.is_available()\n",
    "accelerator =  'gpu' if is_available else 'mps'\n",
    "print(f\"Accelerator: {accelerator}\")\n",
    "train_devices = '0,1' if  is_available else 'auto'\n",
    "test_devices = '0,' if is_available else 'auto'\n",
    "print(f\"train_devices: {train_devices}\")\n",
    "print(f\"test_devices: {test_devices}\")\n",
    "learning_rate = \"0.001\"\n",
    "train_videos = \"[0,1,2,3,4,8,9,10,11,12,13,14,15,16]\"\n",
    "val_videos = \"[5,17,18]\"\n",
    "test_videos = \"[6,7,19,20]\"\n",
    "model_classpath = 'models.HyperGT'\n",
    "experiment_name = 'HyperGT'\n",
    "max_epochs = 100\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "!python train.py fit -c configs/base.yaml \\\n",
    "--trainer.accelerator {accelerator} \\\n",
    "--trainer.devices {train_devices} \\\n",
    "--trainer.logger.save_dir logs/{experiment_name}_clf \\\n",
    "--trainer.enable_progress_bar True \\\n",
    "--trainer.max_epochs {max_epochs} \\\n",
    "--data.num_workers {num_workers} \\\n",
    "--data LmKeyStreamModule \\\n",
    "--data.frames_dir ./datasets/topview/raw_frames \\\n",
    "--data.labels_dir ./datasets/topview/labels \\\n",
    "--data.landmarks_dir ./datasets/topview/landmarks \\\n",
    "--data.train_windows \"[[2,2]]\" \\\n",
    "--data.val_windows \"[[2,2]]\" \\\n",
    "--data.test_windows \"[[2,2]]\" \\\n",
    "--data.train_videos {train_videos} \\\n",
    "--data.val_videos {val_videos} \\\n",
    "--data.test_videos {test_videos} \\\n",
    "--data.batch_size 32 \\\n",
    "--model LmKeyClf \\\n",
    "--model.model_classpath {model_classpath} \\\n",
    "--model.lr 0.001 \\\n",
    "--model.model_init_args.num_class 30 \\\n",
    "--model.model_init_args.in_channels 3 \\\n",
    "--model.model_init_args.num_of_heads 1 \\\n",
    "--model.id2label clf_id2label \\\n",
    "--model.label2id clf_label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ckpt_path, clf_metric_path, clf_config_path = get_ckpt_path(f\"logs/{experiment_name}_clf\")\n",
    "print('clf_config_path: ', clf_config_path)\n",
    "print('clf_metric_path: ', clf_metric_path)\n",
    "print('clf_ckpt_path: ', clf_ckpt_path)\n",
    "# test\n",
    "!python train.py test -c {clf_config_path} \\\n",
    "--trainer.accelerator {accelerator} \\\n",
    "--trainer.devices {test_devices} \\\n",
    "--ckpt_path {clf_ckpt_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "!python train.py fit -c configs/base.yaml \\\n",
    "--trainer.accelerator {accelerator} \\\n",
    "--trainer.devices {train_devices} \\\n",
    "--trainer.logger.save_dir logs/{experiment_name}_det \\\n",
    "--trainer.enable_progress_bar False \\\n",
    "--trainer.max_epochs {max_epochs} \\\n",
    "--data.num_workers {num_workers} \\\n",
    "--data LmKeyStreamModule \\\n",
    "--data.frames_dir ./datasets/topview/raw_frames \\\n",
    "--data.labels_dir ./datasets/topview/labels \\\n",
    "--data.landmarks_dir ./datasets/topview/landmarks \\\n",
    "--data.train_windows \"[[2,2]]\" \\\n",
    "--data.val_windows \"[[2,2]]\" \\\n",
    "--data.test_windows \"[[2,2]]\" \\\n",
    "--data.train_videos {train_videos} \\\n",
    "--data.val_videos {val_videos} \\\n",
    "--data.test_videos {test_videos} \\\n",
    "--data.batch_size 32 \\\n",
    "--data.idle_gap 1 \\\n",
    "--model LmKeyClf \\\n",
    "--model.model_classpath {model_classpath} \\\n",
    "--model.lr 0.001 \\\n",
    "--model.model_init_args.num_class 2 \\\n",
    "--model.model_init_args.in_channels 3 \\\n",
    "--model.model_init_args.num_of_heads 1 \\\n",
    "--model.id2label detect_id2label \\\n",
    "--model.label2id detect_label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_ckpt_path, det_metric_path, det_config_path = get_ckpt_path(f\"logs/{experiment_name}_det\")\n",
    "print('det_ckpt_path: ', det_ckpt_path)\n",
    "\n",
    "!python train.py test -c {det_config_path} \\\n",
    "--trainer.accelerator {accelerator} \\\n",
    "--trainer.devices {test_devices} \\\n",
    "--ckpt_path {det_ckpt_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py \\\n",
    "--data_dir ./datasets/topview/landmarks \\\n",
    "--clf_ckpt ckpts/HyperGT/clf/epoch=15-step=1744.ckpt \\\n",
    "--det_ckpt ckpts/HyperGT/det/epoch=16-step=2312.ckpt \\\n",
    "--result_dir ckpts/HyperGT/stream_results \\\n",
    "--window_size 8 \\\n",
    "--videos 7 \\\n",
    "--module_classpath lightning_utils.lm_module.LmKeyClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.realtime_util import process_prediction\n",
    "\n",
    "prediction = process_prediction('ckpts/HyperGT/stream_results/7.csv', active_thres=0.5, key_thres=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = \"\"\"Dear Team, I hope you all had a fantastic time. Our recent teamwork and appreciation are truly uplifting to see everyone come together and enjoy the best activities. Our enthusiasm and initiative made the event a resounding success. We want to take a moment to express our heartfelt gratitude for your hard work and dedication. It's like these small tokens of appreciation for the incredible effort you put into your roles every day. As we move forward, let's carry this spirit of camaraderie, contribution, and innovation to our continued success, and we look forward to achieving even greater milestones together. Once again, thank you for being an integral part of our team. Here's to continued success and many more memorable moments ahead. Best regards, Katy.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.realtime_util import evaluate\n",
    "gt = \"dear team, i hope you all had a fantastic time, our recent employee appreciation event. it was truly a pleasure to see everyone come together and enjoy the festivities. your enthusiasm and positive enery made the event a resounding success. we wanted to take a moment to extend our heartfelt gratitude to each of your hard work and dedication. events like these are a small token of appreciation for the incredible effort you put into your roles every day. as we move forward, lets carry forward this spirit of camaraderies and teamwork. your contributions are invaluable to our company success, and we look forward to achieveing even greater milestones together. once again, thank you for being an integral part of our team. heres to continue success and many more memorable moments ahead. best regards, katty\"\n",
    "evaluate(corrected, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.realtime_util import process_prediction, evaluate, remove_consecutive_letters\n",
    "\n",
    "prediction = process_prediction('ckpts/HyperGT-small/stream_results/6.csv', active_thres=0.5, key_thres=0.8)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_consecutive_letters(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = \"Dear Fuincy, I hope you are doing well. I wanted to update you on our latest project, which has been quite the journey. The work involves a series of complex tasks, each with its own unique challenges. Our team, including Kenvin and Czelada, has been diligently working to tackle these issues. Recently, we faced several quirky situations that required immediate action. Thankfully, we managed to resolve them with the help of our innovative techniques and quick adjustments. The process has been quite rigorous, but we are making significant strides. Our project is driven by advanced algorithms and cutting-edge technology. Key aspects include data analysis, sifting through extensive datasets, and precise measurements. We've had to navigate through tricky scenarios, but we are confident in the direction we are heading. If you have any questions or need more details, feel free to reach out. I'm available for a quick call if that would be more convenient. Your feedback and insights are highly valued and will help us ensure the project meets all expectations. Thank you for your continued support and understanding. We look forward to sharing more updates with you soon. Best regards, Jack A. Izimer.\"\n",
    "gt = \"dear quincy, i hope you are doing well. i wanted to update you our latest project, which has been quite the journey. the work involves a series of complex tasks, each with its uniques challenges. our team, including kevin and zelda, has been diligently working to tackle these issues. recently we faced several quirky situations that required immediate attention. thankfully, we managed to address them with the help of our innovative techniques and quick adjustments. the process has been quite rigorous, but we are making significant strides. our project is driven by advanced algorithms and cutting edge technology. the key aspects include xray data analysis, zipping through extensive datasets, and precise measurments. we have had to navigate through tricky scenarios, but we are confident in the direction we are heading. if you have any questions or need more details, please feel free to reach out. we are available for a quick call if that would be more convenient. your feedback and insights are highly valued and will help us ensure the project meets all expectiations. thank you for your continued support and undertanding. we look forward to sharing more updates with you soon. best regards, jack q. zimmer.\"\n",
    "evaluate(corrected, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperGT-small-lr0.0001\n",
    "# Correction text: https://chatgpt.com/share/66f1e90b-9cf4-8012-b78c-13b5b53a0086\n",
    "from utils.realtime_util import process_prediction, evaluate, remove_consecutive_letters\n",
    "pred_6 = process_prediction('ckpts/HyperGT-small-lr0.0001/stream_results/6.csv', active_thres=0.5, key_thres=0.9)\n",
    "pred_6 = remove_consecutive_letters(pred_6)\n",
    "print(pred_6)\n",
    "corrected_6 = \"Odiear Quincy, I hope you are doing well. I wanted to update you on our latest project, which has been quite the journey. The work involves a series of complex tasks, each with its unique challenges. Our team, including Kevin and Xzed, has been diligently working to tackle these issues. Recently, we faced several quirky situations that required immediate attention. Thankfully, we managed to address them with the help of innovative techniques and quick adjustments. The process has been quite rigorous, but we are making significant strides. Our project is driven by advanced algorithms and cutting-edge technology. Key aspects include data analysis, working with extensive datasets, and precise measurements. We've had to navigate through tricky scenarios, but we are confident in the direction we're heading. If you have any questions or need more details, please feel free to reach out. We're available for a quick call if that would be more convenient. Your feedback and insights are highly valued and will help us ensure the project meets all expectations. Thank you for your continued support and understanding. We look forward to sharing more updates with you soon. Best regards, Jack A. Izizmer.\"\n",
    "gt_6 = \"dear quincy, i hope you are doing well. i wanted to update you our latest project, which has been quite the journey. the work involves a series of complex tasks, each with its uniques challenges. our team, including kevin and zelda, has been diligently working to tackle these issues. recently we faced several quirky situations that required immediate attention. thankfully, we managed to address them with the help of our innovative techniques and quick adjustments. the process has been quite rigorous, but we are making significant strides. our project is driven by advanced algorithms and cutting edge technology. the key aspects include xray data analysis, zipping through extensive datasets, and precise measurments. we have had to navigate through tricky scenarios, but we are confident in the direction we are heading. if you have any questions or need more details, please feel free to reach out. we are available for a quick call if that would be more convenient. your feedback and insights are highly valued and will help us ensure the project meets all expectiations. thank you for your continued support and undertanding. we look forward to sharing more updates with you soon. best regards, jack q. zimmer.\"\n",
    "evaluate(corrected_6, gt_6)\n",
    "\n",
    "pred_7 = process_prediction('ckpts/HyperGT-small-lr0.0001/stream_results/7.csv', active_thres=0.5, key_thres=0.8)\n",
    "pred_7 = remove_consecutive_letters(pred_7)\n",
    "print(pred_7)\n",
    "gt_7 = \"dear team, i hope you all had a fantastic time, our recent employee appreciation event. it was truly a pleasure to see everyone come together and enjoy the festivities. your enthusiasm and positive enery made the event a resounding success. we wanted to take a moment to extend our heartfelt gratitude to each of your hard work and dedication. events like these are a small token of appreciation for the incredible effort you put into your roles every day. as we move forward, lets carry forward this spirit of camaraderies and teamwork. your contributions are invaluable to our company success, and we look forward to achieveing even greater milestones together. once again, thank you for being an integral part of our team. heres to continue success and many more memorable moments ahead. best regards, katty\"\n",
    "corrected_7 = \"Dear Team, I hope you all had a fantastic time at our recent appreciation event. It was truly a pleasure to see everyone come together and enjoy the activities. Your enthusiasm and positive energy made the event a resounding success. We wanted to take a moment to extend our heartfelt gratitude for all your hard work and dedication. Events like these are a small token of appreciation for the incredible effort you put into your roles every day. As we move forward, let's carry on this spirit of camaraderie and teamwork. Your contributions are invaluable to our company's success, and we look forward to achieving even greater milestones together. Once again, thank you for being an integral part of our team. Here's to continued success and many more memorable moments ahead. Best regards, Keatya.\"\n",
    "evaluate(corrected_7, gt_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all neccessary files\n",
    "!mkdir clf\n",
    "!mkdir det\n",
    "!cp {clf_ckpt_path} clf\n",
    "!cp {clf_metric_path} clf\n",
    "!cp {clf_config_path} clf\n",
    "!cp clf_test_results.csv clf\n",
    "!cp {det_ckpt_path} det\n",
    "!cp {det_metric_path} det \n",
    "!cp {det_config_path} det\n",
    "!cp det_test_results.csv det\n",
    "!zip -r {experiment_name}.zip stream_results clf det\n",
    "\n",
    "!cp {experiment_name}.zip ..\n",
    "# Delete the git repo to save space\n",
    "%cd ..\n",
    "!rm -r Keystroke-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "!python train.py fit -c configs/base.yaml \\\n",
    "--trainer.accelerator cpu \\\n",
    "--trainer.devices auto \\\n",
    "--trainer.logger.save_dir logs/resnet_clf \\\n",
    "--trainer.enable_progress_bar True \\\n",
    "--trainer.max_epochs 1 \\\n",
    "--data.num_workers 0 \\\n",
    "--data KeyStreamModule \\\n",
    "--data.frames_dir ./datasets/topview/raw_frames \\\n",
    "--data.labels_dir ./datasets/topview/labels \\\n",
    "--data.train_windows \"[[3,4]]\" \\\n",
    "--data.val_windows \"[[3,4]]\" \\\n",
    "--data.test_windows \"[[3,4]]\" \\\n",
    "--data.train_videos \"[0,1,2,3,4]\" \\\n",
    "--data.val_videos \"[5]\" \\\n",
    "--data.test_videos \"[6,7]\" \\\n",
    "--data.batch_size 3 \\\n",
    "--model KeyClf \\\n",
    "--model.model_classpath models.resnet101 \\\n",
    "--model.lr 0.001 \\\n",
    "--model.model_init_args.sample_size 50 \\\n",
    "--model.id2label clf_id2label \\\n",
    "--model.label2id clf_label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lightning/fabric/utilities/seed.py:42: No seed found, seed set to 0\n",
      "Seed set to 0\n",
      "Key counts: \n",
      "      label   0    1    2    3    4\n",
      "0    comma   3   13    9   10  270\n",
      "1      dot   4   17   19   22   24\n",
      "2   delete  27   77  111   98  202\n",
      "3    space  66  189  223  240  282\n",
      "4        a  25   79   99   88  138\n",
      "5        b   6    9    7   19   27\n",
      "6        c  11   53   42   36   52\n",
      "7        d  13   33   40   34   43\n",
      "8        e  47  142  150  127  185\n",
      "9        f  10   20   15   15   17\n",
      "10       g   5   31   31   20   46\n",
      "11       h  14   25   43   47   41\n",
      "12       i  17   82   83   88  105\n",
      "13       j   2    2    8    1   10\n",
      "14       k   2   11   15    8   30\n",
      "15       l  20   44   43   40   92\n",
      "16       m   8   24   16   26   32\n",
      "17       n  19   77   76   88  114\n",
      "18       o  32   66   84   68  132\n",
      "19       p   3   15   36   33   43\n",
      "20       q   1    1    8    0   10\n",
      "21       r  20   83   71   59  120\n",
      "22       s  12   57   73   63   49\n",
      "23       t  26   83   84   88   96\n",
      "24       u  11   35   39   35   58\n",
      "25       v   4   11   16   10   25\n",
      "26       w   4   11   20   27   26\n",
      "27       x   0    4    8    4   13\n",
      "28       y   8   22   21   23   25\n",
      "29       z   0    0    3    1   19\n",
      "Total samples:  6973\n",
      "Key counts: \n",
      "      label    5\n",
      "0    comma   11\n",
      "1      dot   21\n",
      "2   delete   87\n",
      "3    space  169\n",
      "4        a   44\n",
      "5        b   21\n",
      "6        c   24\n",
      "7        d   29\n",
      "8        e   81\n",
      "9        f   22\n",
      "10       g   20\n",
      "11       h   20\n",
      "12       i   60\n",
      "13       j   17\n",
      "14       k   16\n",
      "15       l   32\n",
      "16       m   19\n",
      "17       n   32\n",
      "18       o   58\n",
      "19       p   19\n",
      "20       q   20\n",
      "21       r   36\n",
      "22       s   32\n",
      "23       t   46\n",
      "24       u   33\n",
      "25       v   17\n",
      "26       w   19\n",
      "27       x   19\n",
      "28       y   23\n",
      "29       z   18\n",
      "Total samples:  1065\n",
      "Key counts: \n",
      "      label    6    7\n",
      "0    comma   14    6\n",
      "1      dot   17    9\n",
      "2   delete   81   76\n",
      "3    space  213  146\n",
      "4        a   88   73\n",
      "5        b   10    6\n",
      "6        c   34   22\n",
      "7        d   48   29\n",
      "8        e  140  103\n",
      "9        f   14   17\n",
      "10       g   25   10\n",
      "11       h   42   19\n",
      "12       i   79   39\n",
      "13       j    6    2\n",
      "14       k   16    8\n",
      "15       l   38   19\n",
      "16       m   21   22\n",
      "17       n   73   46\n",
      "18       o   64   65\n",
      "19       p   20   13\n",
      "20       q   13    0\n",
      "21       r   63   59\n",
      "22       s   62   37\n",
      "23       t   89   68\n",
      "24       u   48   26\n",
      "25       v   16   13\n",
      "26       w   20   10\n",
      "27       x    4    1\n",
      "28       y   21   18\n",
      "29       z    3    0\n",
      "Total samples:  2344\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | Net                | 3.0 M  | train\n",
      "1 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "3.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 M     Total params\n",
      "12.145    Total estimated model params size (MB)\n",
      "451       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "Sanity Checking DataLoader 0: 100%|███████████████| 2/2 [00:00<00:00,  7.83it/s]EPOCH 0 val_acc 0.0\n",
      "/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "Epoch 0:   1%|▎                      | 30/2325 [00:12<16:29,  2.32it/s, v_num=4]^C\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "!python train.py fit -c configs/base.yaml \\\n",
    "--trainer.accelerator cpu \\\n",
    "--trainer.devices auto \\\n",
    "--trainer.logger.save_dir logs/resnet_clf \\\n",
    "--trainer.enable_progress_bar True \\\n",
    "--trainer.max_epochs 1 \\\n",
    "--data.num_workers 0 \\\n",
    "--data KeyStreamModule \\\n",
    "--data.frames_dir ./datasets/topview/raw_frames \\\n",
    "--data.labels_dir ./datasets/topview/labels \\\n",
    "--data.train_windows \"[[3,4]]\" \\\n",
    "--data.val_windows \"[[3,4]]\" \\\n",
    "--data.test_windows \"[[3,4]]\" \\\n",
    "--data.train_videos \"[0,1,2,3,4]\" \\\n",
    "--data.val_videos \"[5]\" \\\n",
    "--data.test_videos \"[6,7]\" \\\n",
    "--data.batch_size 3 \\\n",
    "--model KeyClf \\\n",
    "--model.model_classpath pytorchvideo.models.x3d.create_x3d \\\n",
    "--model.lr 0.001 \\\n",
    "--model.model_init_args.input_clip_length 8 \\\n",
    "--model.model_init_args.model_num_class 30 \\\n",
    "--model.model_init_args.input_crop_size 60 \\\n",
    "--model.id2label clf_id2label \\\n",
    "--model.label2id clf_label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchvideo.models.x3d import create_x3d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
