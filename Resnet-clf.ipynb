{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install torch lightning torchvision pyav"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Training hyperparameters\n","IMG_SIZE = 112\n","FRAMES_PER_VIDEO = 8\n","NUM_CLASSES = 30\n","LEARNING_RATE = 0.001\n","BATCH_SIZE = 4\n","MAX_EPOCHS = 1000\n","MAX_TIME = \"00:11:00:00\"\n","\n","# Dataset\n","DATA_DIR = \"./datasets/key_clf_data_112_112\"\n","NUM_WORKERS = 4\n","\n","FAST_DEV_RUN = True\n","CHECKPOINT_DIR = \"restnet/\"\n","\n","# Compute related\n","ACCELERATOR = \"cpu\"\n","DEVICES = 0"]},{"cell_type":"markdown","metadata":{},"source":["# Resnet 3D"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T00:49:55.134139Z","iopub.status.busy":"2024-06-25T00:49:55.133768Z","iopub.status.idle":"2024-06-25T00:49:57.120516Z","shell.execute_reply":"2024-06-25T00:49:57.119255Z","shell.execute_reply.started":"2024-06-25T00:49:55.134109Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import math\n","from functools import partial\n","\n","\n","def conv3x3x3(in_planes, out_planes, stride=1):\n","    # 3x3x3 convolution with padding\n","    return nn.Conv3d(\n","        in_planes,\n","        out_planes,\n","        kernel_size=3,\n","        stride=stride,\n","        padding=1,\n","        bias=False)\n","\n","\n","def downsample_basic_block(x, planes, stride):\n","    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n","    zero_pads = torch.Tensor(\n","        out.size(0), \n","        planes - out.size(1), \n","        out.size(2), \n","        out.size(3),\n","        out.size(4)\n","    ).zero_()\n","    \n","    if isinstance(out.data, torch.cuda.FloatStorage):\n","        zero_pads = zero_pads.cuda()\n","\n","    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n","\n","    return out\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm3d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm3d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm3d(planes)\n","\n","        self.conv2 = nn.Conv3d(\n","            planes, planes, \n","            kernel_size=3, stride=stride, padding=1, \n","            bias=False)\n","        self.bn2 = nn.BatchNorm3d(planes)\n","        \n","        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm3d(planes * 4)\n","        \n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self,\n","                 block,\n","                 layers,\n","                 sample_size,\n","                 sample_duration,\n","                 shortcut_type='B',\n","                 num_classes=400):\n","        \n","        \"\"\"\n","        block: basic block or bottle neck\n","        layers: define Resnet architecture 34, 101, 152 etc\n","        sample size: image size\n","        shortcut_type: 'A' or 'B'\n","        num_classes: ...\n","        \"\"\"\n","        self.inplanes = 64\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv3d(\n","            3,\n","            64,\n","            kernel_size=7,\n","            stride=(1, 2, 2),\n","            padding=(3, 3, 3),\n","            bias=False)\n","        self.bn1 = nn.BatchNorm3d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n","\n","\n","        self.layer1 = self._make_layer(\n","            block, 64, layers[0], shortcut_type)\n","        self.layer2 = self._make_layer(\n","            block, 128, layers[1], shortcut_type, stride=2)\n","        self.layer3 = self._make_layer(\n","            block, 256, layers[2], shortcut_type, stride=2)\n","        self.layer4 = self._make_layer(\n","            block, 512, layers[3], shortcut_type, stride=2)\n","        \n","        \n","        last_duration = int(math.ceil(sample_duration / 16))\n","        last_size = int(math.ceil(sample_size / 32))\n","        self.avgpool = nn.AvgPool3d(\n","            (last_duration, last_size, last_size), stride=1)\n","        \n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv3d):\n","                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n","            elif isinstance(m, nn.BatchNorm3d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            if shortcut_type == 'A':\n","                downsample = partial(\n","                    downsample_basic_block,\n","                    planes=planes * block.expansion,\n","                    stride=stride)\n","            else:\n","                downsample = nn.Sequential(\n","                    nn.Conv3d(\n","                        self.inplanes,\n","                        planes * block.expansion,\n","                        kernel_size=1,\n","                        stride=stride,\n","                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","def get_fine_tuning_parameters(model, ft_portion):\n","    if ft_portion == \"complete\":\n","        return model.parameters()\n","\n","    elif ft_portion == \"last_layer\":\n","        ft_module_names = []\n","        ft_module_names.append('classifier')\n","\n","        parameters = []\n","        for k, v in model.named_parameters():\n","            for ft_module in ft_module_names:\n","                if ft_module in k:\n","                    parameters.append({'params': v})\n","                    break\n","            else:\n","                parameters.append({'params': v, 'lr': 0.0})\n","        return parameters\n","    else:\n","        raise ValueError(\"Unsupported ft_portion: 'complete' or 'last_layer' expected\")\n","\n","\n","def resnet10(**kwargs):\n","    \"\"\"Constructs a ResNet-18 model.\n","    \"\"\"\n","    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n","    return model\n","\n","\n","def resnet18(**kwargs):\n","    \"\"\"Constructs a ResNet-18 model.\n","    \"\"\"\n","    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n","    return model\n","\n","\n","def resnet34(**kwargs):\n","    \"\"\"Constructs a ResNet-34 model.\n","    \"\"\"\n","    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n","    return model\n","\n","\n","def resnet50(**kwargs):\n","    \"\"\"Constructs a ResNet-50 model.\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n","    return model\n","\n","\n","def resnet101(**kwargs):\n","    \"\"\"Constructs a ResNet-101 model.\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n","    return model\n","\n","\n","def resnet152(**kwargs):\n","    \"\"\"Constructs a ResNet-101 model.\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n","    return model\n","\n","\n","def resnet200(**kwargs):\n","    \"\"\"Constructs a ResNet-101 model.\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T00:50:06.263645Z","iopub.status.busy":"2024-06-25T00:50:06.263099Z","iopub.status.idle":"2024-06-25T00:50:06.284193Z","shell.execute_reply":"2024-06-25T00:50:06.282890Z","shell.execute_reply.started":"2024-06-25T00:50:06.263599Z"},"trusted":true},"outputs":[],"source":["import pathlib\n","import torch\n","# from GesRec.models.resnet import resnet101\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.io import read_video\n","import lightning as L\n","from lightning.pytorch.loggers import CSVLogger\n","import torchmetrics\n","from lightning.pytorch.callbacks import EarlyStopping\n","\n","class KeyClf(L.LightningModule):\n","    def __init__(self, img_size, frames_per_video, num_classes, learning_rate):\n","        super().__init__()\n","        self.model = resnet101(sample_size=img_size,\n","                 sample_duration=frames_per_video,\n","                 shortcut_type='A',\n","                 num_classes=num_classes)\n","        \n","        self.loss_fn = torch.nn.CrossEntropyLoss(torch.tensor(\n","            [0.3786, 3.4687, 0.2339, 5.1575, 0.5353, 2.7603, 1.2979, 1.3481, 0.3588,\n","            2.4195, 2.2690, 1.3504, 0.5582, 4.5445, 5.3329, 0.9848, 1.8958, 0.6644,\n","            0.6276, 1.7267, 5.6196, 0.6950, 0.8535, 0.5532, 1.1135, 4.1810, 2.9921,\n","             3.6377, 2.1390, 4.0409]))\n","        self.accuracy = torchmetrics.Accuracy(\n","            task=\"multiclass\", num_classes=num_classes\n","        )\n","\n","        self.training_step_outputs = []\n","        self.validate_step_outputs = []\n","\n","        self.lr = learning_rate\n","\n","\n","    def training_step(self, batch):\n","        videos, targets = batch\n","        preds = self.model(videos)\n","        loss = self.loss_fn(preds, targets.long())\n","        self.training_step_outputs.append({\"preds\": preds, \"targets\": targets})\n","\n","        return loss\n","    \n","    def on_training_epoch_end(self):\n","        preds = torch.cat(outputs[\"preds\"] for outputs in self.training_step_outputs)\n","        targets = torch.cat(outputs[\"targets\"] for outputs in self.training_step_outputs)\n","       \n","        self.log_dict(\n","            {\n","                \"train_acc\": self.accuracy(preds, targets),\n","            },\n","            on_step=False,\n","            on_epoch=True,\n","            prog_bar=True,\n","        )\n","\n","\n","        self.training_step_outputs.clear()\n","\n","\n","    def validation_step(self, batch):\n","        videos, targets = batch\n","        preds = self.model(videos)\n","        loss = self.loss_fn(preds, targets.long())\n","        self.validate_step_outputs.append({\"preds\": preds, \"targets\": targets})\n","\n","        return loss\n","    \n","    \n","    def on_validation_epoch_end(self):\n","        preds = torch.cat(outputs[\"preds\"] for outputs in self.validate_step_outputs)\n","        targets = torch.cat(outputs[\"targets\"] for outputs in self.validate_step_outputs)\n","       \n","        self.log_dict(\n","            {\n","                \"val_acc\": self.accuracy(preds, targets),\n","                \"val_loss\": \n","            },\n","            on_step=False,\n","            on_epoch=True,\n","            prog_bar=True,\n","        )\n","\n","        self.validate_step_outputs.clear()\n","    \n","        \n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.model.parameters(), lr=self.lr)\n","    \n","class KeyStrokeClsDataset(Dataset):\n","    def __init__(self, data_dir, mode):\n","        self.dataset_root_path = pathlib.Path(data_dir)\n","        self.all_video_file_paths =  list(self.dataset_root_path.glob(f\"{mode}/*/*.mp4\"))\n","\n","        self.class_labels = sorted({str(path).split(\"/\")[-2] for path in self.all_video_file_paths})\n","        \n","        self.label2id = {label: i for i, label in enumerate(self.class_labels)}\n","        self.id2label  = {i: label for label, i in self.label2id.items()}\n","  \n","    def __len__(self):\n","        return len(self.all_video_file_paths)\n","\n","    def __getitem__(self, idx):\n","        file_path = self.all_video_file_paths[idx]\n","        vframes, _, _ = read_video(file_path, pts_unit='sec')\n","        label = str(file_path).split(\"/\")[-2]\n","\n","        # permute to (num_frames, num_channels, height, width)\n","        vframes = vframes.permute(3, 0, 1, 2).float() / 255.0\n","    \n","        return vframes, self.label2id[label]\n","\n","\n","class KeyClsData(L.LightningDataModule):\n","    def __init__(self, batch_size, data_dir):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.dataset_root_path = pathlib.Path(data_dir)\n","        self.data_dir = data_dir\n","   \n","        \n","    def train_dataloader(self):\n","        train_dataset = KeyStrokeClsDataset(self.data_dir, 'train')\n","        print(\"Train dataset:\", len(train_dataset))\n","        return DataLoader(train_dataset, batch_size=self.batch_size, num_workers=NUM_WORKERS, persistent_workers=True)\n","    \n","    def val_dataloader(self):\n","        val_dataset = KeyStrokeClsDataset(self.data_dir, 'val')\n","        print(\"Val dataset:\", len(val_dataset))\n","        return DataLoader(val_dataset, batch_size=self.batch_size, num_workers=NUM_WORKERS, persistent_workers=True)\n","    \n","    def test_dataloader(self):\n","        test_dataset = KeyStrokeClsDataset(self.data_dir, 'test')\n","        print(\"Test dataset:\", len(test_dataset))\n","        return DataLoader(test_dataset, batch_size=self.batch_size, num_workers=NUM_WORKERS, persistent_workers=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/9w/wb24vz290fx3x35b66j6pds80000gn/T/ipykernel_51145/562908493.py:164: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n","GPU available: True (mps), used: False\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n","Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n","\n","  | Name     | Type               | Params | Mode \n","--------------------------------------------------------\n","0 | model    | ResNet             | 82.5 M | train\n","1 | loss_fn  | CrossEntropyLoss   | 0      | train\n","2 | accuracy | MulticlassAccuracy | 0      | train\n","--------------------------------------------------------\n","82.5 M    Trainable params\n","0         Non-trainable params\n","82.5 M    Total params\n","330.120   Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Train dataset: 47036\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'KeyStrokeClsDataset' on <module '__main__' (built-in)>\n","/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"]}],"source":["logger = CSVLogger(\"logs\", name=\"restnet_test\")\n","data = KeyClsData(batch_size=BATCH_SIZE, data_dir=DATA_DIR)\n","model = KeyClf(img_size=IMG_SIZE, \n","            frames_per_video=FRAMES_PER_VIDEO,\n","            num_classes=NUM_CLASSES, \n","            learning_rate=LEARNING_RATE,)\n","\n","logger = CSVLogger(\"logs\", name=f\"resnet\")\n","trainer = L.Trainer(\n","    deterministic=True,\n","    # devices=DEVICES,\n","    max_time=MAX_TIME,\n","    callbacks=[EarlyStopping(monitor=\"val_loss\")],\n","    default_root_dir=CHECKPOINT_DIR,\n","    fast_dev_run=FAST_DEV_RUN,\n","    logger=logger,\n","    accelerator=ACCELERATOR\n",")\n","trainer.fit(model, data)"]},{"cell_type":"markdown","metadata":{},"source":["**TEST**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T00:51:36.994176Z","iopub.status.busy":"2024-06-25T00:51:36.993757Z","iopub.status.idle":"2024-06-25T02:23:30.864032Z","shell.execute_reply":"2024-06-25T02:23:30.862875Z","shell.execute_reply.started":"2024-06-25T00:51:36.994142Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","test_dataset = KeyStrokeClsDataset(\"/kaggle/input/keystroker-classify/keystroke_classify_data\", 'test')\n","\n","id2Label = ['BackSpace', 'Comma', 'Space', 'Stop', \n","            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', \n","            'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', \n","            'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n","            'y', 'z']\n","\n","model = KeyClf.load_from_checkpoint('/kaggle/working/clf_train_batch_8_max_epochs_10')\n","model.eval()\n","y = []\n","predictions = []\n","with torch.no_grad():\n","    for video, label in tqdm(test_dataset):\n","        logits = model.model(video.unsqueeze(0))\n","        y_pred = id2Label[torch.argmax(logits, dim=1).item()]\n","        predictions.append(y_pred)\n","        y.append(id2Label[label])\n","        # print(f\"y_pred: {y_pred}; y: {id2Label[label]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T02:27:27.425990Z","iopub.status.busy":"2024-06-25T02:27:27.425547Z","iopub.status.idle":"2024-06-25T02:27:27.507128Z","shell.execute_reply":"2024-06-25T02:27:27.505917Z","shell.execute_reply.started":"2024-06-25T02:27:27.425955Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","\n","print(classification_report(y, predictions))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T02:30:15.207101Z","iopub.status.busy":"2024-06-25T02:30:15.206696Z","iopub.status.idle":"2024-06-25T02:30:17.960307Z","shell.execute_reply":"2024-06-25T02:30:17.959106Z","shell.execute_reply.started":"2024-06-25T02:30:15.207069Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","\n","# Create confusion matrix\n","cm = confusion_matrix(y, predictions)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(16, 12))\n","sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=id2Label, yticklabels=id2Label)\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["47036"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = KeyStrokeClsDataset(DATA_DIR, 'train')\n","len(train_dataset)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5275321,"sourceId":8776942,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
