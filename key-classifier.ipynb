{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc85765b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:40:43.743819Z",
     "iopub.status.busy": "2024-07-17T13:40:43.742780Z",
     "iopub.status.idle": "2024-07-17T13:40:59.836052Z",
     "shell.execute_reply": "2024-07-17T13:40:59.835101Z"
    },
    "papermill": {
     "duration": 16.103548,
     "end_time": "2024-07-17T13:40:59.838563",
     "exception": false,
     "start_time": "2024-07-17T13:40:43.735015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\r\n",
      "  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\r\n",
      "Collecting einops\r\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.3.1)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\r\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\r\n",
      "Requirement already satisfied: torch<4.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\r\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.4.0.post0)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.9.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (69.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.0.0->lightning) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.0.0->lightning) (1.3.0)\r\n",
      "Downloading lightning-2.3.3-py3-none-any.whl (808 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: einops, lightning\r\n",
      "Successfully installed einops-0.8.0 lightning-2.3.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning torchvision einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a6bee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:40:59.856508Z",
     "iopub.status.busy": "2024-07-17T13:40:59.856138Z",
     "iopub.status.idle": "2024-07-17T13:41:11.390012Z",
     "shell.execute_reply": "2024-07-17T13:41:11.389022Z"
    },
    "papermill": {
     "duration": 11.545815,
     "end_time": "2024-07-17T13:41:11.392564",
     "exception": false,
     "start_time": "2024-07-17T13:40:59.846749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from functools import partial\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_video\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import torchmetrics\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchvision.transforms import CenterCrop, v2\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0b4bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:11.408987Z",
     "iopub.status.busy": "2024-07-17T13:41:11.408552Z",
     "iopub.status.idle": "2024-07-17T13:41:11.415493Z",
     "shell.execute_reply": "2024-07-17T13:41:11.414639Z"
    },
    "papermill": {
     "duration": 0.016983,
     "end_time": "2024-07-17T13:41:11.417303",
     "exception": false,
     "start_time": "2024-07-17T13:41:11.400320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2Label = ['[i]', 'BackSpace', ',', '[s]', '.', \n",
    "            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', \n",
    "            'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', \n",
    "            'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "            'y', 'z']\n",
    "label2Id  = {label: i for i, label in enumerate(id2Label)}\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "f_after = 2 # number of frames after\n",
    "f_before = 2 # number of frames before\n",
    "gap = 2 # gap between idle video segment and non-idle video segment\n",
    "total_window = f_after + f_before + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14cfba",
   "metadata": {
    "papermill": {
     "duration": 0.006978,
     "end_time": "2024-07-17T13:41:11.431417",
     "exception": false,
     "start_time": "2024-07-17T13:41:11.424439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefe7fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:11.447046Z",
     "iopub.status.busy": "2024-07-17T13:41:11.446750Z",
     "iopub.status.idle": "2024-07-17T13:41:11.481100Z",
     "shell.execute_reply": "2024-07-17T13:41:11.480196Z"
    },
    "papermill": {
     "duration": 0.044846,
     "end_time": "2024-07-17T13:41:11.483278",
     "exception": false,
     "start_time": "2024-07-17T13:41:11.438432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### RESNET 3D #### \n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    # 3x3x3 convolution with padding\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def downsample_basic_block(x, planes, stride):\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(out.size(0), planes - out.size(1), out.size(2), out.size(3), out.size(4) ).zero_()\n",
    "    \n",
    "    if isinstance(out.data, torch.cuda.FloatStorage): zero_pads = zero_pads.cuda()\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "    return out\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            planes, planes, \n",
    "            kernel_size=3, stride=stride, padding=1, \n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, sample_size, sample_duration, shortcut_type='B', num_classes=400):\n",
    "        \"\"\"\n",
    "        block: basic block or bottle neck\n",
    "        layers: define Resnet architecture 34, 101, 152 etc\n",
    "        sample size: image size\n",
    "        shortcut_type: 'A' or 'B'\n",
    "        num_classes: ...\n",
    "        \"\"\"\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=7, stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], shortcut_type, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], shortcut_type, stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], shortcut_type, stride=2)\n",
    "        \n",
    "        \n",
    "        last_duration = int(math.ceil(sample_duration / 16))\n",
    "        last_size = int(math.ceil(sample_size / 32))\n",
    "        self.avgpool = nn.AvgPool3d(\n",
    "            (last_duration, last_size, last_size), stride=1)\n",
    "        \n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(self.inplanes,planes * block.expansion,kernel_size=1,stride=stride,bias=False), \n",
    "                    nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet10(**kwargs): return ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "def resnet18(**kwargs): return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "def resnet34(**kwargs): return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "def resnet50(**kwargs): return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "def resnet101(**kwargs): return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "def resnet152(**kwargs): return ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "def resnet200(**kwargs): return ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d8e5c",
   "metadata": {
    "papermill": {
     "duration": 0.006974,
     "end_time": "2024-07-17T13:41:11.497781",
     "exception": false,
     "start_time": "2024-07-17T13:41:11.490807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22e5a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:11.513844Z",
     "iopub.status.busy": "2024-07-17T13:41:11.513545Z",
     "iopub.status.idle": "2024-07-17T13:41:13.160822Z",
     "shell.execute_reply": "2024-07-17T13:41:13.159879Z"
    },
    "papermill": {
     "duration": 1.658248,
     "end_time": "2024-07-17T13:41:13.163445",
     "exception": false,
     "start_time": "2024-07-17T13:41:11.505197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from 2020 Ross Wightman\n",
    "https://github.com/rwightman/pytorch-image-models\n",
    "\"\"\"\n",
    "import torch\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.models.vision_transformer import _load_weights\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import DropPath\n",
    "import torch\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        trunc_normal_(m.weight, std=0.02)\n",
    "        if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        nn.init.constant_(m.weight, 1.0)\n",
    "        \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout, out_dim=None):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, hidden_dim)\n",
    "        self.act = nn.GELU()\n",
    "        if out_dim is None:\n",
    "            out_dim = dim\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    @property\n",
    "    def unwrapped(self):\n",
    "        return self\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        head_dim = dim // heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        self.attn = None\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(dropout)\n",
    "\n",
    "    @property\n",
    "    def unwrapped(self):\n",
    "        return self\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, N, C = x.shape\n",
    "        qkv = (\n",
    "            self.qkv(x)\n",
    "            .reshape(B, N, 3, self.heads, C // self.heads)\n",
    "            .permute(2, 0, 3, 1, 4)\n",
    "        )\n",
    "        \n",
    "        q, k, v = (\n",
    "            qkv[0],\n",
    "            qkv[1],\n",
    "            qkv[2],\n",
    "        )\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "       \n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "    \n",
    "        return x, attn\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, heads, mlp_dim, dropout, drop_path):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.attn = Attention(dim, heads, dropout)\n",
    "        self.mlp = FeedForward(dim, mlp_dim, dropout)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x, mask=None, return_attention=False):\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        y, attn = self.attn(x, mask)\n",
    "        if return_attention:\n",
    "            return attn\n",
    "        x = x + self.drop_path(y)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        frames,\n",
    "        n_layers,\n",
    "        d_model,\n",
    "        d_ff,\n",
    "        n_heads,\n",
    "        n_cls,\n",
    "        dropout=0.1,\n",
    "        drop_path_rate=0.0,\n",
    "        distilled=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "#         self.patch_embed = PatchEmbedding(\n",
    "#             image_size,\n",
    "#             patch_size,\n",
    "#             d_model,\n",
    "#             channels,\n",
    "#         )\n",
    "        # self.patch_size = patch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.n_cls = n_cls\n",
    "\n",
    "        # cls and pos tokens\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        self.distilled = distilled\n",
    "        if self.distilled:\n",
    "            self.dist_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "            self.pos_embed = nn.Parameter(\n",
    "                torch.randn(1, frames + 2, d_model)\n",
    "            )\n",
    "            self.head_dist = nn.Linear(d_model, n_cls)\n",
    "        else:\n",
    "            self.pos_embed = nn.Parameter(\n",
    "                torch.randn(1, frames + 1, d_model)\n",
    "            )\n",
    "\n",
    "        # transformer blocks\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, n_layers)]\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(d_model, n_heads, d_ff, dropout, dpr[i]) for i in range(n_layers)]\n",
    "        )\n",
    "\n",
    "        # output head\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.head = nn.Linear(d_model, n_cls)\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=0.02)\n",
    "        trunc_normal_(self.cls_token, std=0.02)\n",
    "        if self.distilled:\n",
    "            trunc_normal_(self.dist_token, std=0.02)\n",
    "        self.pre_logits = nn.Identity()\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {\"pos_embed\", \"cls_token\", \"dist_token\"}\n",
    "\n",
    "    @torch.jit.ignore()\n",
    "    def load_pretrained(self, checkpoint_path, prefix=\"\"):\n",
    "        _load_weights(self, checkpoint_path, prefix)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        B, N, C, H, W = x.shape\n",
    "        x = x.flatten(2)\n",
    "#         print(x.shape)\n",
    "   \n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "#         print(cls_tokens.shape)\n",
    "        if self.distilled:\n",
    "            dist_tokens = self.dist_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, dist_tokens, x), dim=1)\n",
    "        else:\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "#         print(x.shape)\n",
    "        pos_embed = self.pos_embed\n",
    "#         print(pos_embed.shape)\n",
    "        x = x + pos_embed\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if self.distilled:\n",
    "            x, x_dist = x[:, 0], x[:, 1]\n",
    "            x = self.head(x)\n",
    "            x_dist = self.head_dist(x_dist)\n",
    "            x = (x + x_dist) / 2\n",
    "        else:\n",
    "            x = x[:, 0]\n",
    "            x = self.head(x)\n",
    "        return x\n",
    "\n",
    "vit = VisionTransformer(frames=total_window, n_layers=20, d_model=2*21*3, d_ff=256, n_heads=6, n_cls=len(id2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12b8cd",
   "metadata": {
    "papermill": {
     "duration": 0.007273,
     "end_time": "2024-07-17T13:41:13.179198",
     "exception": false,
     "start_time": "2024-07-17T13:41:13.171925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lightning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff61fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:13.195132Z",
     "iopub.status.busy": "2024-07-17T13:41:13.194827Z",
     "iopub.status.idle": "2024-07-17T13:41:13.225394Z",
     "shell.execute_reply": "2024-07-17T13:41:13.224455Z"
    },
    "papermill": {
     "duration": 0.041009,
     "end_time": "2024-07-17T13:41:13.227330",
     "exception": false,
     "start_time": "2024-07-17T13:41:13.186321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KeyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_name, labels_dir, videos_dir):\n",
    "        segments = []\n",
    "        # Infer idle frames.\n",
    "        self.labels_dir = labels_dir\n",
    "        self.videos_dir = videos_dir\n",
    "        df = pd.read_csv(f'{self.labels_dir}/{video_name}.csv')\n",
    "        for index, row in df.iterrows():\n",
    "            key_frame = int(row['Frame'])  # Frame number where key was pressed\n",
    "            key_value = row['Key']  # Key pressed\n",
    "            if key_value not in id2Label:\n",
    "                key_value = '[s]'\n",
    "            \n",
    "            is_idle_before = False\n",
    "            if index == 0:\n",
    "                pos_start = max(key_frame - f_before, 0)\n",
    "                pos_end = key_frame + f_after\n",
    "                neg_start = 0\n",
    "                neg_end = pos_start - gap\n",
    "                is_idle_before = True\n",
    "            else:\n",
    "                prev_key_frame = df.iloc[index - 1]['Frame']\n",
    "                pos_start = max(key_frame - f_before, 0)\n",
    "                pos_end = key_frame + f_after\n",
    "                prev_pos_end = prev_key_frame + f_after\n",
    "                if (pos_start - prev_pos_end) - 1 >= (f_after + f_before + 1 + gap * 2):\n",
    "                    neg_start =  prev_pos_end + gap\n",
    "                    neg_end = pos_start - gap\n",
    "                    is_idle_before = True\n",
    "            \n",
    "            \n",
    "            # Negative class video segments before\n",
    "            if is_idle_before:\n",
    "                j = neg_start\n",
    "                while (j + total_window - 1) <= neg_end:\n",
    "                    segments.append(([j, j + total_window - 1], \"[i]\"))\n",
    "                    j += total_window\n",
    "            \n",
    "            # Current video with keystroke\n",
    "            segments.append(([pos_start, pos_end], key_value))\n",
    "        \n",
    "        self.landmarks = torch.load(f'{videos_dir}/{video_name}.pt')\n",
    "        # print(self.landmarks.shape)\n",
    "        self.segments = segments\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        (start, end), label = self.segments[idx]\n",
    "        return self.landmarks[start:end+1], label2Id[label]\n",
    "    \n",
    "    def get_class_counts(self):\n",
    "        labels = [segment[1] for segment in self.segments]\n",
    "        unique_elements, counts = np.unique(labels, return_counts=True)\n",
    "        occurrences = dict(zip(unique_elements, counts))\n",
    "        weights = np.zeros(len(id2Label))\n",
    "        for label, count in occurrences.items():\n",
    "            weights[label2Id[label]] = count\n",
    "        return weights\n",
    "\n",
    "class KeyDataModule(L.LightningDataModule):\n",
    "    def __init__(self, batch_size, labels_dir, videos_dir, train_vids, val_vids, test_vids):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_datasets = [KeyDataset(video_name, labels_dir, videos_dir) for video_name in train_vids]\n",
    "        self.val_datasets = [KeyDataset(video_name, labels_dir, videos_dir) for video_name in val_vids]\n",
    "        self.test_datasets = [KeyDataset(video_name, labels_dir, videos_dir) for video_name in test_vids]\n",
    "        \n",
    "        self.train_dataset = torch.utils.data.ConcatDataset(self.train_datasets)\n",
    "        self.test_dataset = torch.utils.data.ConcatDataset(self.test_datasets)\n",
    "        self.val_dataset = torch.utils.data.ConcatDataset(self.val_datasets)\n",
    "        \n",
    "        print(f\"Train: {len(self.train_dataset)}; Val: {len(self.val_dataset)}; Test: {len(self.test_dataset)}\")\n",
    "        \n",
    "        train_counts = np.array(\n",
    "            [d.get_class_counts() for d in self.train_datasets]).sum(axis=0)\n",
    "        print(f\"Train counts: {train_counts}\")\n",
    "        train_total_samples = np.array([len(d) for d in self.train_datasets]).sum(axis=0)\n",
    "        self.train_weights = train_counts / (train_total_samples * len(id2Label))\n",
    "                                        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, \n",
    "                          batch_size=self.batch_size, \n",
    "                          num_workers=NUM_WORKERS)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, \n",
    "                          batch_size=self.batch_size, \n",
    "                          num_workers=NUM_WORKERS,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, \n",
    "                          batch_size=self.batch_size, \n",
    "                          num_workers=NUM_WORKERS,\n",
    "                          shuffle=False)\n",
    "\n",
    "class KeyClf(L.LightningModule):\n",
    "    def __init__(self, model, num_classes, learning_rate, weights):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(torch.tensor(weights).float())\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.lr = learning_rate\n",
    "#         self.transforms = v2.Compose([\n",
    "#             v2.CenterCrop(img_size),\n",
    "#             v2.ToDtype(torch.float32, scale=True),\n",
    "#         ])\n",
    "        \n",
    "        self.test_preds = []\n",
    "        self.test_targets = []\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "\n",
    "    def _common_step(self, batch):\n",
    "        videos, targets = batch\n",
    "        preds = self.model(videos)\n",
    "        pred_ids = torch.argmax(self.model(videos), dim=1)\n",
    "        loss = self.loss_fn(preds, targets.long())\n",
    "        acc = self.accuracy(preds, targets)\n",
    "        return loss, acc, pred_ids\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        videos, targets = batch\n",
    "        loss, acc, pred_ids = self._common_step(batch)\n",
    "        pred_labels = [id2Label[_id] for _id in pred_ids]\n",
    "        self.test_preds += pred_labels\n",
    "        self.test_targets += [id2Label[_id] for _id in targets]\n",
    "        self.log_dict({'test_loss': loss, 'test_acc': acc})\n",
    "\n",
    "    \n",
    "    def on_test_end(self):\n",
    "        print(classification_report(self.test_targets, self.test_preds))\n",
    "        \n",
    "    def training_step(self, batch):\n",
    "        loss, acc, _ = self._common_step(batch)\n",
    "        self.log_dict({'train_loss': loss, 'train_acc': acc})\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        loss, acc, _ = self._common_step(batch)\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': acc})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c6fcbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:13.243642Z",
     "iopub.status.busy": "2024-07-17T13:41:13.243160Z",
     "iopub.status.idle": "2024-07-17T13:41:13.350183Z",
     "shell.execute_reply": "2024-07-17T13:41:13.349247Z"
    },
    "papermill": {
     "duration": 0.11792,
     "end_time": "2024-07-17T13:41:13.352320",
     "exception": false,
     "start_time": "2024-07-17T13:41:13.234400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 21, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_video_1 = KeyDataset(\n",
    "    'video_1',\n",
    "    labels_dir=\"/kaggle/input/landmarks/labels/labels\",\n",
    "    videos_dir=\"/kaggle/input/landmarks\"\n",
    ")\n",
    "test_video_1[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158677e",
   "metadata": {
    "papermill": {
     "duration": 0.007166,
     "end_time": "2024-07-17T13:41:13.367359",
     "exception": false,
     "start_time": "2024-07-17T13:41:13.360193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a85e206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:13.383358Z",
     "iopub.status.busy": "2024-07-17T13:41:13.383053Z",
     "iopub.status.idle": "2024-07-17T13:41:26.189486Z",
     "shell.execute_reply": "2024-07-17T13:41:26.188446Z"
    },
    "papermill": {
     "duration": 12.816893,
     "end_time": "2024-07-17T13:41:26.191771",
     "exception": false,
     "start_time": "2024-07-17T13:41:13.374878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 77589; Val: 7168; Test: 4377\n",
      "Train counts: [29360.  4182.   532.  7038.   376.  2938.   590.  1222.  1179.  4348.\n",
      "   682.   734.  1228.  2825.   407.   363.  1573.   850.  2352.  2539.\n",
      "   917.   346.  2248.  1843.  2776.  1417.   405.   587.   497.   779.\n",
      "   456.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO: \n",
      "  | Name     | Type               | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model    | VisionTransformer  | 2.6 M  | train\n",
      "1 | loss_fn  | CrossEntropyLoss   | 0      | train\n",
      "2 | accuracy | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.373    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfb96ddf49c44aa9801ee10b0b2a005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3246b6007e0348a78a4e8d5b2bf13771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=1` reached.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbb189a758d4166a7ed7d8bbd0bead9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         [i]       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.3589211702346802     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3589211702346802    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.3589211702346802, 'test_acc': 1.0}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = KeyDataModule(batch_size=8, \n",
    "                   labels_dir=\"/kaggle/input/landmarks/labels/labels\",\n",
    "                    videos_dir=\"/kaggle/input/landmarks\",\n",
    "                   train_vids=[\n",
    "                       'video_1', 'video_2', 'video_3', 'video_4', 'video_5', \n",
    "                        'video_6', 'video_7', 'video_8', 'video_9', 'video_10',\n",
    "                       'video_11', 'video_12', 'video_13', 'video_14', 'video_15', \n",
    "                       'video_16', 'video_17', 'video_18', 'video_19',\n",
    "                       'video_21', 'video_22', 'video_23', 'video_24', 'video_25', \n",
    "                       'video_26', 'video_27', 'video_28', 'video_29', 'video_30'], \n",
    "                   val_vids=['video_31', 'video_32', 'video_33'], \n",
    "                   test_vids=['video_34','video_35', 'video_36'])\n",
    "# resnet = resnet152(sample_size=img_size, sample_duration=total_window, shortcut_type='B', num_classes=len(id2Label))\n",
    "\n",
    "model = KeyClf(vit, num_classes=len(id2Label), \n",
    "               learning_rate=0.001,\n",
    "               weights=dm.train_weights)\n",
    "logger = CSVLogger(\"logs\", name=f\"vit\", flush_logs_every_n_steps=1)\n",
    "trainer = L.Trainer(\n",
    "    # deterministic=True,\n",
    "    devices=[0],\n",
    "    accelerator=\"gpu\",\n",
    "    fast_dev_run=True,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=10)],\n",
    "    logger=logger,\n",
    "    max_epochs=10,\n",
    "    # enable_progress_bar=False\n",
    ")\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b412fed0",
   "metadata": {
    "papermill": {
     "duration": 0.008821,
     "end_time": "2024-07-17T13:41:26.209732",
     "exception": false,
     "start_time": "2024-07-17T13:41:26.200911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Resume training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aceaad88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:26.229901Z",
     "iopub.status.busy": "2024-07-17T13:41:26.229572Z",
     "iopub.status.idle": "2024-07-17T13:41:26.234620Z",
     "shell.execute_reply": "2024-07-17T13:41:26.233699Z"
    },
    "papermill": {
     "duration": 0.017056,
     "end_time": "2024-07-17T13:41:26.236640",
     "exception": false,
     "start_time": "2024-07-17T13:41:26.219584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dm = KeyDataModule(batch_size=8, \n",
    "#                    labels_dir='/kaggle/input/keystroke/labels',\n",
    "#                    videos_dir=\"/kaggle/input/keystroke/raw_frames_320\",\n",
    "#                    train_vids=[\n",
    "#                        'video_1', 'video_2', 'video_3', 'video_4', 'video_5', \n",
    "#                         'video_6', 'video_7', 'video_8', 'video_9', 'video_10',\n",
    "#                        'video_11', 'video_12', 'video_13', 'video_14', 'video_15', \n",
    "#                        'video_16', 'video_17', 'video_18', 'video_19',\n",
    "#                        'video_21', 'video_22', 'video_23', 'video_24', 'video_25', \n",
    "#                        'video_26', 'video_27', 'video_28', 'video_29', 'video_30'], \n",
    "#                    val_vids=['video_31', 'video_32', 'video_33'], \n",
    "#                    test_vids=['video_34', 'video_35', 'video_36'])\n",
    "# model = KeyClf.load_from_checkpoint(\"/kaggle/input/key-clf-smaller/pytorch/v1/1/smaller-epoch10-step53350.ckpt\")\n",
    "# trainer = L.Trainer(\n",
    "#     # deterministic=True,\n",
    "#     accelerator=\"tpu\",\n",
    "#     fast_dev_run=False,\n",
    "#     max_time=\"00:11:00:00\",\n",
    "#     callbacks=[EarlyStopping(monitor=\"val_loss\", patience=10)]\n",
    "# )\n",
    "# trainer.fit(model, dm)\n",
    "# trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4addd",
   "metadata": {
    "papermill": {
     "duration": 0.008486,
     "end_time": "2024-07-17T13:41:26.254063",
     "exception": false,
     "start_time": "2024-07-17T13:41:26.245577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2031a621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:26.273111Z",
     "iopub.status.busy": "2024-07-17T13:41:26.272859Z",
     "iopub.status.idle": "2024-07-17T13:41:26.281199Z",
     "shell.execute_reply": "2024-07-17T13:41:26.280513Z"
    },
    "papermill": {
     "duration": 0.020198,
     "end_time": "2024-07-17T13:41:26.283069",
     "exception": false,
     "start_time": "2024-07-17T13:41:26.262871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trained_model = KeyClf.load_from_checkpoint(\"/kaggle/input/key-clf-smaller/pytorch/v1/1/smaller-epoch10-step53350.ckpt\")\n",
    "\n",
    "# def levenshtein_distance(s1, s2):\n",
    "#     # Initialize a matrix with zeros\n",
    "#     dp = np.zeros((len(s1) + 1, len(s2) + 1), dtype=int)\n",
    "    \n",
    "#     # Initialize first row and column\n",
    "#     for i in range(len(s1) + 1):\n",
    "#         dp[i, 0] = i\n",
    "#     for j in range(len(s2) + 1):\n",
    "#         dp[0, j] = j\n",
    "    \n",
    "#     # Fill the matrix\n",
    "#     for i in range(1, len(s1) + 1):\n",
    "#         for j in range(1, len(s2) + 1):\n",
    "#             cost = 0 if s1[i - 1] == s2[j - 1] else 1\n",
    "#             dp[i, j] = min(dp[i - 1, j] + 1,      # deletion\n",
    "#                            dp[i, j - 1] + 1,      # insertion\n",
    "#                            dp[i - 1, j - 1] + cost)  # substitution\n",
    "    \n",
    "#     # Return the edit distance\n",
    "#     return dp[len(s1), len(s2)]\n",
    "\n",
    "# def similarity_percentage(s1, s2):\n",
    "#     # Calculate the Levenshtein distance\n",
    "#     distance = levenshtein_distance(s1, s2)\n",
    "#     # Calculate the maximum possible distance\n",
    "#     max_distance = max(len(s1), len(s2))\n",
    "#     # Calculate similarity as a percentage\n",
    "#     similarity = 1 - distance / max_distance  \n",
    "#     # Convert to percentage\n",
    "#     similarity_percentage = similarity * 100\n",
    "#     return similarity_percentage\n",
    "\n",
    "# def process_prediction(preds, prob_min = 0.5):\n",
    "#     pred_text = []\n",
    "#     all_keys = preds.iloc[:,1].to_list()\n",
    "#     all_probs = preds.iloc[:, 2].to_list()\n",
    "#     i = 0\n",
    "#     while i < len(preds):\n",
    "#         # Get all the similar keys next to it\n",
    "#         curr_key = all_keys[i]\n",
    "#         # print(''.join(pred_text))\n",
    "#         # print('curr_key: ', curr_key)\n",
    "#         j = i + 1\n",
    "#         while j < len(preds):\n",
    "#             if all_keys[j] != curr_key: \n",
    "#                 j = j - 1\n",
    "#                 break\n",
    "#             j += 1\n",
    "        \n",
    "#         occurences = j - i + 1\n",
    "#         # print('occurences: ', occurences)\n",
    "        \n",
    "#         # Idle keys => skip\n",
    "#         if curr_key == '[i]':\n",
    "#             i = j + 1\n",
    "#             continue\n",
    "\n",
    "#         # Backspace => count how many consecutive bs keys. For 4, remove one prev key \n",
    "#         elif curr_key == 'BackSpace':\n",
    "#             deletions = occurences // 4\n",
    "            \n",
    "#             for _ in range(deletions):\n",
    "#                 if len(pred_text):\n",
    "#                     pred_text.pop()\n",
    "            \n",
    "\n",
    "#         # Other character, less than 4 occurces append once. \n",
    "#         # Else, for the every next 2 occurrence append once (because people press 2 same keys faster)\n",
    "#         else:\n",
    "#             if curr_key == '[s]': curr_key = \" \"\n",
    "#             elif curr_key == '[,]': curr_key = ','\n",
    "#             elif curr_key == '[.]': curr_key = '.'\n",
    "            \n",
    "#             if occurences == 1: \n",
    "#                 if all_probs[i] >= prob_min:\n",
    "#                     pred_text.append(curr_key)\n",
    "                \n",
    "            \n",
    "#             elif occurences <= 4:\n",
    "#                 if max(all_probs[i:j+1]) >= prob_min:\n",
    "#                     pred_text.append(curr_key)\n",
    "                \n",
    "#             else:\n",
    "#                 pred_text.append(curr_key)\n",
    "#                 for _ in range((occurences - 4) // 4):\n",
    "#                     pred_text.append(curr_key)\n",
    "        \n",
    "#         i = j + 1\n",
    "    \n",
    "\n",
    "#     return ''.join(pred_text)\n",
    "\n",
    "# def test_video(video_dir, ground_truth_dir, video_name):\n",
    "#     images = glob.glob(f'{video_dir}/{video}/*.jpg')\n",
    "#     frames = []\n",
    "#     for i in range(len(images)):\n",
    "#         image = torchvision.io.read_image(f\"{video_dir}/{video_name}/frame_{i}.jpg\")\n",
    "#         frames.append(image)\n",
    "#     frames = torch.stack(frames)\n",
    "\n",
    "#     keys = []\n",
    "#     frame_no = []\n",
    "#     probs = []\n",
    "#     trained_model.freeze()\n",
    "#     for i in range(0, len(frames)):\n",
    "#         video = trained_model.transforms(frames[i: i + 5])\n",
    "#         video = video.permute(1, 0, 2, 3)\n",
    "#         out = F.softmax(trained_model.model(video.unsqueeze(0)), 1)[0]\n",
    "#         _id = torch.argmax(out).item()\n",
    "#         label = id2Label[_id]\n",
    "        \n",
    "#         print(f\"Frame {i};{label};{out[_id]}\")\n",
    "#         frame_no.append(i)\n",
    "#         keys.append(label)\n",
    "#         probs.append(out[_id])\n",
    "    \n",
    "#     df = pd.DataFrame({\n",
    "#         'Frame': frame_no,\n",
    "#         'Key': keys,\n",
    "#         'Prob': probs,\n",
    "#     })\n",
    "#     os.makedirs('./test-result', exist_ok=True)\n",
    "#     df.to_csv(f'./test-result/{video_name}.csv', sep=';', index=False)\n",
    "\n",
    "#     pred_text = process_prediction(df)\n",
    "#     print('pred_text: ', pred_text)\n",
    "    \n",
    "#     if ground_truth_dir:\n",
    "#         ground_truth = open(f'{ground_truth_dir}/{video_name}.txt', 'r').read()\n",
    "#         similarity = similarity_percentage(pred_text, ground_truth)\n",
    "#         print('similarity: ', similarity)\n",
    "    \n",
    "#     open(f\"./test-result/{video_name}_processed.txt\", 'w').write(pred_text)\n",
    "\n",
    "# test_video(video_dir = '/kaggle/input/keystroke/raw_frames_320', \n",
    "#            video='video_36',\n",
    "#            ground_truth_dir = '/kaggle/input/keystroke/ground_truths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de176095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:26.302718Z",
     "iopub.status.busy": "2024-07-17T13:41:26.302377Z",
     "iopub.status.idle": "2024-07-17T13:41:26.306815Z",
     "shell.execute_reply": "2024-07-17T13:41:26.305985Z"
    },
    "papermill": {
     "duration": 0.016231,
     "end_time": "2024-07-17T13:41:26.308613",
     "exception": false,
     "start_time": "2024-07-17T13:41:26.292382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_text = 'dr team, i op ouou al ha  fnnasatic time t our recent empohye pprcition ent  t s ta tryuuuly truy a plarsr to s eerne scome to ggehr nd nouy fte estivities . our entunnusism nd ositi enrgy md th ent a resounding succes   we nt ed to ta e  moment to eextend our  herrt  et grrduttidtde to ec of o r hrd ror and ddicttiion  cbent s e thes r sa sml tlon of pprcition or  thde incrdil eort uou put intol ouyourrr ros eer  d d s e mo forrd  s crrt forrdd ths sprit of cmrderies  nd temor  o r contriutions r inuatl to our commpny succs  and  loo orwrd to chingieing  eem greate moile satoonnes gtotogter once gain  , thnn uo fo bining an intergra  prt of our tem here s to continu d scscuc c es nd mn  more mmorae moments esd b st reggards t'\n",
    "# ground_truth = open('/kaggle/input/keystroke/ground_truths/video_35.txt', 'r').read()\n",
    "# similarity = similarity_percentage(pred_text, ground_truth)\n",
    "# similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ef7210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T13:41:26.327312Z",
     "iopub.status.busy": "2024-07-17T13:41:26.327051Z",
     "iopub.status.idle": "2024-07-17T13:41:26.331062Z",
     "shell.execute_reply": "2024-07-17T13:41:26.330243Z"
    },
    "papermill": {
     "duration": 0.015678,
     "end_time": "2024-07-17T13:41:26.333017",
     "exception": false,
     "start_time": "2024-07-17T13:41:26.317339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# corrected = \"dr team, i hope you all had a fantastic time at our recent employee appreciation event. it was truly a pleasure to see everyone come together and enjoy the festivities. your enthusiasm and positive energy made the event a resounding success. we wanted to take a moment to extend our heartfelt gratitude to each of you for your hard work and dedication. events like these are a small token of appreciation for the incredible effort you put into your roles every day. we look forward to carrying forward this spirit of camaraderie and teamwork. your contributions are invaluable to our company's success, and we look forward to achieving even greater milestones together once again. thank you for being an integral part of our team. here's to continued success and many more memorable moments. best regards.\"\n",
    "# similarity = similarity_percentage(corrected, ground_truth)\n",
    "# similarity"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5358145,
     "sourceId": 8911158,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.39443,
   "end_time": "2024-07-17T13:41:29.088321",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-17T13:40:40.693891",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09fec84178ec48b39d379a552fcc77fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "159a3489eca244db984678df060fc17b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_52bea1d04feb4053830a2084d956b1c0",
       "placeholder": "​",
       "style": "IPY_MODEL_b36c57495b6a44cc813b2693675866d4",
       "value": " 1/1 [00:00&lt;00:00,  1.13it/s]"
      }
     },
     "166d70ee055646c29f0e3ee61bf4985a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "194b47dcd07249aab8503ee8581d66eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20f605703ebf4ffc8ea277b379a772e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "25384e904fa8476da6dba15d889b3a23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_09fec84178ec48b39d379a552fcc77fd",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_166d70ee055646c29f0e3ee61bf4985a",
       "value": 1.0
      }
     },
     "263750e03f414ca583ccc00f7e7343d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4e4764fe0104c718155588ec5bb0bc6",
       "placeholder": "​",
       "style": "IPY_MODEL_cf0ccc58215a47f4b8d9920044544f38",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "26bc8d4b8bca4ead9cb8660d0b446c9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_faf4ceed7c5944a29c2efffe04e43052",
       "placeholder": "​",
       "style": "IPY_MODEL_20f605703ebf4ffc8ea277b379a772e1",
       "value": " 1/1 [00:00&lt;00:00, 23.28it/s]"
      }
     },
     "3246b6007e0348a78a4e8d5b2bf13771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9a0337b0a7534b17aa3d1f8ca5db03b4",
        "IPY_MODEL_25384e904fa8476da6dba15d889b3a23",
        "IPY_MODEL_a6770f470ff04f71a62dfc0617f680d9"
       ],
       "layout": "IPY_MODEL_3d2f739144904fea9cb7e51c9ff23929"
      }
     },
     "3d2f739144904fea9cb7e51c9ff23929": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "3dfb96ddf49c44aa9801ee10b0b2a005": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a0af3df6de2240cda82f1b7c7df59fa7",
        "IPY_MODEL_b79c7915954e46a890e9236eec55e360",
        "IPY_MODEL_159a3489eca244db984678df060fc17b"
       ],
       "layout": "IPY_MODEL_873839dcc56e4a2a9646710291ad147b"
      }
     },
     "52bea1d04feb4053830a2084d956b1c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65148820f4e6407f8685465013ae40cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d2c0700cbc74fbf847ecdf516ea28f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "73a6e715e0e946cda4ce7a2abc16d856": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "75d484630f4c4681817ca43937c71ce1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7db1d8e989ca45019833ff27cc7c61e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "873839dcc56e4a2a9646710291ad147b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "8bbb189a758d4166a7ed7d8bbd0bead9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_263750e03f414ca583ccc00f7e7343d8",
        "IPY_MODEL_9d14208008754da0a64cbe9af7ea0d40",
        "IPY_MODEL_26bc8d4b8bca4ead9cb8660d0b446c9d"
       ],
       "layout": "IPY_MODEL_73a6e715e0e946cda4ce7a2abc16d856"
      }
     },
     "8e8128e4c0df4d8daf68eaeadbc710cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a0337b0a7534b17aa3d1f8ca5db03b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8e8128e4c0df4d8daf68eaeadbc710cd",
       "placeholder": "​",
       "style": "IPY_MODEL_e4eeaaeba0744b01aa406008156b15b0",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "9d14208008754da0a64cbe9af7ea0d40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75d484630f4c4681817ca43937c71ce1",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6d2c0700cbc74fbf847ecdf516ea28f2",
       "value": 1.0
      }
     },
     "a0af3df6de2240cda82f1b7c7df59fa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7db1d8e989ca45019833ff27cc7c61e7",
       "placeholder": "​",
       "style": "IPY_MODEL_e812cbed04174ecf84290a47bd2c2ce9",
       "value": "Epoch 0: 100%"
      }
     },
     "a6770f470ff04f71a62dfc0617f680d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_194b47dcd07249aab8503ee8581d66eb",
       "placeholder": "​",
       "style": "IPY_MODEL_dd896eb66bc645dd9baaae78efc54f59",
       "value": " 1/1 [00:00&lt;00:00, 27.59it/s]"
      }
     },
     "b36c57495b6a44cc813b2693675866d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b79c7915954e46a890e9236eec55e360": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_65148820f4e6407f8685465013ae40cb",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e0011431cf5f45fb95b395fdc76a6f72",
       "value": 1.0
      }
     },
     "cf0ccc58215a47f4b8d9920044544f38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dd896eb66bc645dd9baaae78efc54f59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e0011431cf5f45fb95b395fdc76a6f72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e4eeaaeba0744b01aa406008156b15b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e812cbed04174ecf84290a47bd2c2ce9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f4e4764fe0104c718155588ec5bb0bc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "faf4ceed7c5944a29c2efffe04e43052": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
