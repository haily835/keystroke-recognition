{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20d86ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:27:14.413482Z",
     "iopub.status.busy": "2024-07-10T05:27:14.413083Z",
     "iopub.status.idle": "2024-07-10T05:27:29.643853Z",
     "shell.execute_reply": "2024-07-10T05:27:29.642909Z"
    },
    "papermill": {
     "duration": 15.240021,
     "end_time": "2024-07-10T05:27:29.646152",
     "exception": false,
     "start_time": "2024-07-10T05:27:14.406131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\r\n",
      "  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\r\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.3.1)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\r\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\r\n",
      "Requirement already satisfied: torch<4.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\r\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.4.0.post0)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.9.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (69.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.0.0->lightning) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.0.0->lightning) (1.3.0)\r\n",
      "Downloading lightning-2.3.3-py3-none-any.whl (808 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lightning\r\n",
      "Successfully installed lightning-2.3.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad6de08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:27:29.660175Z",
     "iopub.status.busy": "2024-07-10T05:27:29.659662Z",
     "iopub.status.idle": "2024-07-10T05:27:40.142462Z",
     "shell.execute_reply": "2024-07-10T05:27:40.141624Z"
    },
    "papermill": {
     "duration": 10.492183,
     "end_time": "2024-07-10T05:27:40.144763",
     "exception": false,
     "start_time": "2024-07-10T05:27:29.652580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from functools import partial\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_video\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import torchmetrics\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchvision.transforms import CenterCrop, v2\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97bf46e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:27:40.158360Z",
     "iopub.status.busy": "2024-07-10T05:27:40.157964Z",
     "iopub.status.idle": "2024-07-10T05:27:40.164974Z",
     "shell.execute_reply": "2024-07-10T05:27:40.164125Z"
    },
    "papermill": {
     "duration": 0.015705,
     "end_time": "2024-07-10T05:27:40.166816",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.151111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2Label = ['[i]', 'BackSpace', ',', '[s]', '.', \n",
    "            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', \n",
    "            'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', \n",
    "            'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "            'y', 'z']\n",
    "label2Id  = {label: i for i, label in enumerate(id2Label)}\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "f_after = 2 # number of frames after\n",
    "f_before = 2 # number of frames before\n",
    "gap = 2 # gap between idle video segment and non-idle video segment\n",
    "total_window = f_after + f_before + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73e0c6",
   "metadata": {
    "papermill": {
     "duration": 0.00566,
     "end_time": "2024-07-10T05:27:40.178402",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.172742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce6d5af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:27:40.191598Z",
     "iopub.status.busy": "2024-07-10T05:27:40.191238Z",
     "iopub.status.idle": "2024-07-10T05:27:40.224696Z",
     "shell.execute_reply": "2024-07-10T05:27:40.223922Z"
    },
    "papermill": {
     "duration": 0.042533,
     "end_time": "2024-07-10T05:27:40.226733",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.184200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### RESNET 3D #### \n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    # 3x3x3 convolution with padding\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def downsample_basic_block(x, planes, stride):\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(out.size(0), planes - out.size(1), out.size(2), out.size(3), out.size(4) ).zero_()\n",
    "    \n",
    "    if isinstance(out.data, torch.cuda.FloatStorage): zero_pads = zero_pads.cuda()\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "    return out\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            planes, planes, \n",
    "            kernel_size=3, stride=stride, padding=1, \n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, sample_size, sample_duration, shortcut_type='B', num_classes=400):\n",
    "        \"\"\"\n",
    "        block: basic block or bottle neck\n",
    "        layers: define Resnet architecture 34, 101, 152 etc\n",
    "        sample size: image size\n",
    "        shortcut_type: 'A' or 'B'\n",
    "        num_classes: ...\n",
    "        \"\"\"\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=7, stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], shortcut_type, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], shortcut_type, stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], shortcut_type, stride=2)\n",
    "        \n",
    "        \n",
    "        last_duration = int(math.ceil(sample_duration / 16))\n",
    "        last_size = int(math.ceil(sample_size / 32))\n",
    "        self.avgpool = nn.AvgPool3d(\n",
    "            (last_duration, last_size, last_size), stride=1)\n",
    "        \n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(self.inplanes,planes * block.expansion,kernel_size=1,stride=stride,bias=False), \n",
    "                    nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet10(**kwargs): return ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "def resnet18(**kwargs): return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "def resnet34(**kwargs): return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "def resnet50(**kwargs): return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "def resnet101(**kwargs): return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "def resnet152(**kwargs): return ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "def resnet200(**kwargs): return ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e17036",
   "metadata": {
    "papermill": {
     "duration": 0.005634,
     "end_time": "2024-07-10T05:27:40.238134",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.232500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lightning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b83b9c5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:27:40.252050Z",
     "iopub.status.busy": "2024-07-10T05:27:40.251802Z",
     "iopub.status.idle": "2024-07-10T05:27:40.281900Z",
     "shell.execute_reply": "2024-07-10T05:27:40.281043Z"
    },
    "papermill": {
     "duration": 0.038811,
     "end_time": "2024-07-10T05:27:40.283713",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.244902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KeyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_name, labels_dir, videos_dir):\n",
    "        segments = []\n",
    "        # Infer idle frames.\n",
    "        self.labels_dir = labels_dir\n",
    "        self.videos_dir = videos_dir\n",
    "        df = pd.read_csv(f'{self.labels_dir}/{video_name}.csv')\n",
    "        for index, row in df.iterrows():\n",
    "            key_frame = int(row['Frame'])  # Frame number where key was pressed\n",
    "            key_value = row['Key']  # Key pressed\n",
    "            if key_value not in id2Label:\n",
    "                key_value = '[s]'\n",
    "            \n",
    "            is_idle_before = False\n",
    "            if index == 0:\n",
    "                pos_start = max(key_frame - f_before, 0)\n",
    "                pos_end = key_frame + f_after\n",
    "                neg_start = 0\n",
    "                neg_end = pos_start - gap\n",
    "                is_idle_before = True\n",
    "            else:\n",
    "                prev_key_frame = df.iloc[index - 1]['Frame']\n",
    "                pos_start = max(key_frame - f_before, 0)\n",
    "                pos_end = key_frame + f_after\n",
    "                prev_pos_end = prev_key_frame + f_after\n",
    "                if (pos_start - prev_pos_end) - 1 >= (f_after + f_before + 1 + gap * 2):\n",
    "                    neg_start =  prev_pos_end + gap\n",
    "                    neg_end = pos_start - gap\n",
    "                    is_idle_before = True\n",
    "            \n",
    "            \n",
    "            # Negative class video segments before\n",
    "            if is_idle_before:\n",
    "                j = neg_start\n",
    "                while (j + total_window - 1) <= neg_end:\n",
    "                    segments.append(([j, j + total_window - 1], \"[i]\"))\n",
    "                    j += total_window\n",
    "            \n",
    "            # Current video with keystroke\n",
    "            segments.append(([pos_start, pos_end], key_value))\n",
    "        \n",
    "        self.video_name = video_name\n",
    "        self.segments = segments\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        (start, end), label = self.segments[idx]\n",
    "        \n",
    "        frames = []\n",
    "        for i in range(start, end + 1):\n",
    "            image = torchvision.io.read_image(f\"{self.videos_dir}/{self.video_name}/frame_{i}.jpg\")\n",
    "            \n",
    "            frames.append(image)\n",
    "       \n",
    "        return torch.stack(frames), label2Id[label]\n",
    "    \n",
    "    def get_class_counts(self):\n",
    "        labels = [segment[1] for segment in self.segments]\n",
    "        unique_elements, counts = np.unique(labels, return_counts=True)\n",
    "        occurrences = dict(zip(unique_elements, counts))\n",
    "        weights = np.zeros(len(id2Label))\n",
    "        for label, count in occurrences.items():\n",
    "            weights[label2Id[label]] = count\n",
    "        return weights\n",
    "\n",
    "class KeyDataModule(L.LightningDataModule):\n",
    "    def __init__(self, batch_size, labels_dir, videos_dir, train_vids, val_vids, test_vids):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_datasets = [KeyDataset(video_name, labels_dir, videos_dir) for video_name in train_vids]\n",
    "        self.val_datasets = [KeyDataset(video_name, labels_dir, videos_dir) for video_name in val_vids]\n",
    "        self.test_datasets = [KeyDataset(video_name, labels_dir, videos_dir) for video_name in test_vids]\n",
    "        \n",
    "        self.train_dataset = torch.utils.data.ConcatDataset(self.train_datasets)\n",
    "        self.test_dataset = torch.utils.data.ConcatDataset(self.test_datasets)\n",
    "        self.val_dataset = torch.utils.data.ConcatDataset(self.val_datasets)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"Train: {len(self.train_dataset)}; Val: {len(self.val_dataset)}; Test: {len(self.test_dataset)}\")\n",
    "        \n",
    "        train_counts = np.array(\n",
    "            [d.get_class_counts() for d in self.train_datasets]).sum(axis=0)\n",
    "        print(f\"Train counts: {train_counts}\")\n",
    "        train_total_samples = np.array([len(d) for d in self.train_datasets]).sum(axis=0)\n",
    "        self.train_weights = train_counts / (train_total_samples * len(id2Label))\n",
    "                                        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, \n",
    "                          batch_size=self.batch_size, \n",
    "                          num_workers=NUM_WORKERS)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, \n",
    "                          batch_size=self.batch_size, \n",
    "                          num_workers=NUM_WORKERS,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, \n",
    "                          batch_size=self.batch_size, \n",
    "                          num_workers=NUM_WORKERS,\n",
    "                          shuffle=False)\n",
    "\n",
    "class KeyClf(L.LightningModule):\n",
    "    def __init__(self, img_size, num_classes, learning_rate, weights):\n",
    "        super().__init__()\n",
    "        self.model = resnet34(sample_size=img_size, \n",
    "                               sample_duration=total_window,\n",
    "                               shortcut_type='B', \n",
    "                               num_classes=num_classes)\n",
    "        \n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(torch.tensor(weights).float())\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.lr = learning_rate\n",
    "        self.transforms = v2.Compose([\n",
    "            v2.CenterCrop(img_size),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "        ])\n",
    "        \n",
    "        self.test_preds = []\n",
    "        self.test_targets = []\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        videos, targets = batch\n",
    "        videos = self.transforms(videos)\n",
    "        videos = videos.permute(0, 2, 1, 3, 4)\n",
    "        preds = self.model(videos)\n",
    "\n",
    "        pred_ids = torch.argmax(self.model(videos), dim=1).squeeze()\n",
    "        pred_labels = [id2Label[_id] for _id in pred_ids]\n",
    "        self.test_preds += pred_labels\n",
    "        self.test_targets += [id2Label[_id] for _id in targets]\n",
    "        \n",
    "        loss = self.loss_fn(preds, targets.long())\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', self.accuracy(preds, targets))\n",
    "    \n",
    "    def on_test_end(self):\n",
    "        print(classification_report(self.test_targets, self.test_preds))\n",
    "        \n",
    "    def training_step(self, batch):\n",
    "        videos, targets = batch\n",
    "        videos = self.transforms(videos)\n",
    "        videos = videos.permute(0, 2, 1, 3, 4)\n",
    "        preds = self.model(videos)\n",
    "        loss = self.loss_fn(preds, targets.long())\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', self.accuracy(preds, targets))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        videos, targets = batch\n",
    "        videos = self.transforms(videos)\n",
    "        videos = videos.permute(0, 2, 1, 3, 4)\n",
    "        preds = self.model(videos)\n",
    "        loss = self.loss_fn(preds, targets.long())\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', self.accuracy(preds, targets))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d6f7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:27:40.296621Z",
     "iopub.status.busy": "2024-07-10T05:27:40.295961Z",
     "iopub.status.idle": "2024-07-10T05:27:40.366328Z",
     "shell.execute_reply": "2024-07-10T05:27:40.365688Z"
    },
    "papermill": {
     "duration": 0.078883,
     "end_time": "2024-07-10T05:27:40.368326",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.289443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_video_1 = KeyDataset('video_1', \n",
    "                          labels_dir='/kaggle/input/keystroke/labels',\n",
    "                           videos_dir=\"/kaggle/input/keystroke/raw_frames_320\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313aee22",
   "metadata": {
    "papermill": {
     "duration": 0.00569,
     "end_time": "2024-07-10T05:27:40.379893",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.374203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca59809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:27:40.392592Z",
     "iopub.status.busy": "2024-07-10T05:27:40.392251Z",
     "iopub.status.idle": "2024-07-10T05:27:40.396968Z",
     "shell.execute_reply": "2024-07-10T05:27:40.396184Z"
    },
    "papermill": {
     "duration": 0.013082,
     "end_time": "2024-07-10T05:27:40.398762",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.385680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dm = KeyDataModule(batch_size=8, \n",
    "#                    labels_dir='/kaggle/input/keystroke/labels',\n",
    "#                    videos_dir=\"/kaggle/input/keystroke/raw_frames_320\",\n",
    "#                    train_vids=[\n",
    "#                        'video_1', 'video_2', 'video_3', 'video_4', 'video_5', \n",
    "#                         'video_6', 'video_7', 'video_8', 'video_9', 'video_10',\n",
    "#                        'video_11', 'video_12', 'video_13', 'video_14', 'video_15', \n",
    "#                        'video_16', 'video_17', 'video_18', 'video_19',\n",
    "#                        'video_21', 'video_22', 'video_23', 'video_24', 'video_25', \n",
    "#                        'video_26', 'video_27', 'video_28', 'video_29', 'video_30'], \n",
    "#                    val_vids=['video_31', 'video_32', 'video_33'], \n",
    "#                    test_vids=['video_34','video_35', 'video_36'])\n",
    "# model = KeyClf(img_size=320, num_classes=len(id2Label), learning_rate=0.001, weights=dm.train_weights)\n",
    "# trainer = L.Trainer(\n",
    "#     # deterministic=True,\n",
    "#     devices=[0, 1],\n",
    "#     accelerator=\"gpu\",\n",
    "#     fast_dev_run=False,\n",
    "#     max_time=\"00:05:00:00\",\n",
    "#     callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    "# )\n",
    "# trainer.fit(model, dm)\n",
    "# trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271c1f5",
   "metadata": {
    "papermill": {
     "duration": 0.005558,
     "end_time": "2024-07-10T05:27:40.410246",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.404688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Resume training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a70450a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:27:40.422768Z",
     "iopub.status.busy": "2024-07-10T05:27:40.422494Z",
     "iopub.status.idle": "2024-07-10T05:30:11.700889Z",
     "shell.execute_reply": "2024-07-10T05:30:11.699476Z"
    },
    "papermill": {
     "duration": 151.287115,
     "end_time": "2024-07-10T05:30:11.703158",
     "exception": false,
     "start_time": "2024-07-10T05:27:40.416043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 77589; Val: 7168; Test: 4377\n",
      "Train counts: [29360.  4182.   532.  7038.   376.  2938.   590.  1222.  1179.  4348.\n",
      "   682.   734.  1228.  2825.   407.   363.  1573.   850.  2352.  2539.\n",
      "   917.   346.  2248.  1843.  2776.  1417.   405.   587.   497.   779.\n",
      "   456.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/4267700438.py:121: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "INFO: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "WARNING: Missing logger folder: /kaggle/working/lightning_logs\n",
      "INFO: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "WARNING: Missing logger folder: /kaggle/working/lightning_logs\n",
      "2024-07-10 05:27:52.852553: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-10 05:27:52.852690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-10 05:27:53.015228: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "INFO: Restoring states from the checkpoint path at /kaggle/input/key-clf-smaller/pytorch/v1/1/smaller-epoch10-step53350.ckpt\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO: Time limit reached. Elapsed time is 10:18:54. Signaling Trainer to stop.\n",
      "INFO: \n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model      | ResNet             | 63.5 M | train\n",
      "1 | loss_fn    | CrossEntropyLoss   | 0      | train\n",
      "2 | accuracy   | MulticlassAccuracy | 0      | train\n",
      "3 | transforms | Compose            | 0      | train\n",
      "----------------------------------------------------------\n",
      "63.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "63.5 M    Total params\n",
      "254.118   Total estimated model params size (MB)\n",
      "INFO: Restored all states from the checkpoint at /kaggle/input/key-clf-smaller/pytorch/v1/1/smaller-epoch10-step53350.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8365f0f1884989a4f2b4809924eb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('val_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "INFO: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "INFO: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "2024-07-10 05:28:18.108632: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-10 05:28:18.108748: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-10 05:28:18.110701: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ff4d480db94c7792cc5cd69200e802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           ,       1.00      0.14      0.25         7\n",
      "           .       0.00      0.00      0.00        11\n",
      "   BackSpace       0.99      0.58      0.73       147\n",
      "         [i]       0.53      0.98      0.69       549\n",
      "         [s]       0.97      0.92      0.95       246\n",
      "           a       0.97      0.36      0.52       109\n",
      "           b       0.67      0.18      0.29        11\n",
      "           c       0.89      0.82      0.86        51\n",
      "           d       0.94      0.82      0.88        40\n",
      "           e       0.96      0.54      0.69       148\n",
      "           f       1.00      0.22      0.36        18\n",
      "           g       0.95      0.81      0.88        26\n",
      "           h       0.96      0.63      0.76        38\n",
      "           i       1.00      0.69      0.82       113\n",
      "           j       0.00      0.00      0.00         2\n",
      "           k       0.67      0.25      0.36         8\n",
      "           l       1.00      0.26      0.42        42\n",
      "           m       0.94      0.84      0.89        37\n",
      "           n       0.89      0.96      0.92        77\n",
      "           o       0.96      0.81      0.88       109\n",
      "           p       0.96      0.65      0.77        34\n",
      "           q       0.00      0.00      0.00         1\n",
      "           r       0.92      0.67      0.78        98\n",
      "           s       0.94      0.72      0.82        69\n",
      "           t       0.93      0.84      0.89       102\n",
      "           u       0.91      0.72      0.81        40\n",
      "           v       1.00      0.09      0.17        11\n",
      "           w       0.50      0.07      0.12        15\n",
      "           y       0.94      0.57      0.71        28\n",
      "           z       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.75      2189\n",
      "   macro avg       0.78      0.51      0.57      2189\n",
      "weighted avg       0.84      0.75      0.75      2189\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('test_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           ,       1.00      0.38      0.55         8\n",
      "           .       1.00      0.10      0.17        21\n",
      "   BackSpace       0.98      0.63      0.76       134\n",
      "         [i]       0.53      0.98      0.69       567\n",
      "         [s]       0.96      0.94      0.95       231\n",
      "           a       1.00      0.22      0.37        98\n",
      "           b       0.67      0.22      0.33         9\n",
      "           c       0.91      0.80      0.85        40\n",
      "           d       0.97      0.88      0.93        43\n",
      "           e       0.96      0.49      0.65       163\n",
      "           f       1.00      0.39      0.56        23\n",
      "           g       0.88      0.70      0.78        20\n",
      "           h       0.94      0.53      0.68        32\n",
      "           i       0.93      0.78      0.85        89\n",
      "           j       1.00      0.50      0.67         2\n",
      "           k       1.00      0.08      0.14        13\n",
      "           l       0.94      0.32      0.48        47\n",
      "           m       0.86      0.88      0.87        34\n",
      "           n       0.93      0.93      0.93        95\n",
      "           o       0.94      0.74      0.83        88\n",
      "           p       0.88      0.50      0.64        28\n",
      "           q       0.00      0.00      0.00         3\n",
      "           r       0.95      0.83      0.89        89\n",
      "           s       0.93      0.79      0.85        67\n",
      "           t       0.94      0.81      0.87       125\n",
      "           u       0.89      0.63      0.74        54\n",
      "           v       1.00      0.16      0.27        19\n",
      "           w       1.00      0.12      0.22        16\n",
      "           x       0.00      0.00      0.00         1\n",
      "           y       1.00      0.07      0.12        30\n",
      "\n",
      "    accuracy                           0.74      2189\n",
      "   macro avg       0.87      0.51      0.59      2189\n",
      "weighted avg       0.84      0.74      0.73      2189\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7446322441101074     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33599114418029785    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7446322441101074    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33599114418029785   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.33599114418029785, 'test_acc': 0.7446322441101074}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = KeyDataModule(batch_size=8, \n",
    "                   labels_dir='/kaggle/input/keystroke/labels',\n",
    "                   videos_dir=\"/kaggle/input/keystroke/raw_frames_320\",\n",
    "                   train_vids=[\n",
    "                       'video_1', 'video_2', 'video_3', 'video_4', 'video_5', \n",
    "                        'video_6', 'video_7', 'video_8', 'video_9', 'video_10',\n",
    "                       'video_11', 'video_12', 'video_13', 'video_14', 'video_15', \n",
    "                       'video_16', 'video_17', 'video_18', 'video_19',\n",
    "                       'video_21', 'video_22', 'video_23', 'video_24', 'video_25', \n",
    "                       'video_26', 'video_27', 'video_28', 'video_29', 'video_30'], \n",
    "                   val_vids=['video_31', 'video_32', 'video_33'], \n",
    "                   test_vids=['video_34','video_35', 'video_36'])\n",
    "model = KeyClf(img_size=320, num_classes=len(id2Label), learning_rate=0.001, weights=dm.train_weights)\n",
    "trainer = L.Trainer(\n",
    "    # deterministic=True,\n",
    "    devices=[0, 1],\n",
    "    accelerator=\"gpu\",\n",
    "    fast_dev_run=False,\n",
    "    max_time=\"00:05:00:00\",\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=10)],\n",
    ")\n",
    "trainer.fit(model, dm,  ckpt_path = \"/kaggle/input/key-clf-smaller/pytorch/v1/1/smaller-epoch10-step53350.ckpt\")\n",
    "trainer.test(model, dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3318084f",
   "metadata": {
    "papermill": {
     "duration": 0.009394,
     "end_time": "2024-07-10T05:30:11.722475",
     "exception": false,
     "start_time": "2024-07-10T05:30:11.713081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6a5099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:30:11.744210Z",
     "iopub.status.busy": "2024-07-10T05:30:11.743531Z",
     "iopub.status.idle": "2024-07-10T05:30:11.747769Z",
     "shell.execute_reply": "2024-07-10T05:30:11.746910Z"
    },
    "papermill": {
     "duration": 0.017274,
     "end_time": "2024-07-10T05:30:11.749567",
     "exception": false,
     "start_time": "2024-07-10T05:30:11.732293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cuda')\n",
    "# trained_model = KeyClf.load_from_checkpoint(\"/kaggle/input/keyclf/pytorch/v1/1/epoch7-step34979.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d3d751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:30:11.771040Z",
     "iopub.status.busy": "2024-07-10T05:30:11.770778Z",
     "iopub.status.idle": "2024-07-10T05:30:11.774948Z",
     "shell.execute_reply": "2024-07-10T05:30:11.774111Z"
    },
    "papermill": {
     "duration": 0.016572,
     "end_time": "2024-07-10T05:30:11.776766",
     "exception": false,
     "start_time": "2024-07-10T05:30:11.760194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# video = 'video_36'\n",
    "# images = glob.glob(f'/kaggle/input/keycls-test/test_data/raw_frames/{video}/*.jpg')\n",
    "# img = cv2.imread(os.path.join(input_dir, jpg_files[0]))\n",
    "# height, width, _ = img.shape\n",
    "\n",
    "# output_file = f'./{video}.mp4'\n",
    "# # Define the codec and create VideoWriter object\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 format\n",
    "# out = cv2.VideoWriter(output_file, fourcc, framerate=25, (width, height))\n",
    "\n",
    "# # Iterate through JPG files and write to video\n",
    "# for i in range(len(images)):\n",
    "#     img = cv2.imread(''/kaggle/input/keycls-test/test_data/raw_frames/{video}/frame_{i}.jpg')\n",
    "#     out.write(img)\n",
    "\n",
    "# # Release VideoWriter and close all windows\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def76c35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:30:11.797387Z",
     "iopub.status.busy": "2024-07-10T05:30:11.797119Z",
     "iopub.status.idle": "2024-07-10T05:30:11.801925Z",
     "shell.execute_reply": "2024-07-10T05:30:11.800869Z"
    },
    "papermill": {
     "duration": 0.017443,
     "end_time": "2024-07-10T05:30:11.803932",
     "exception": false,
     "start_time": "2024-07-10T05:30:11.786489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds = []\n",
    "\n",
    "# is_gpu = torch.cuda.is_available()\n",
    "\n",
    "# if is_gpu: \n",
    "#     trained_model.to(device)\n",
    "\n",
    "# trained_model.freeze()\n",
    "# i = 0\n",
    "# recording = True\n",
    "# window = []\n",
    "\n",
    "# while recording:\n",
    "#     # Less than 8 flen(window)rames => continue to collect frames....\n",
    "#     if len(window) < total_window:\n",
    "#         image = torchvision.io.read_image(f\"/kaggle/input/keycls-test/test_data/raw_frames/{video}/frame_{i}.jpg\")\n",
    "#         window.append(image)\n",
    "#     if len(window) == total_window:\n",
    "#         frames = torch.stack(window)\n",
    "#         frames = trained_model.transforms(frames)\n",
    "#         frames = frames.permute(1, 0, 2, 3)\n",
    "        \n",
    "#         if is_gpu: frames.to(device)\n",
    "#         out = F.softmax(trained_model.model(frames.unsqueeze(0)))[0]\n",
    "#         _id = torch.argmax(out)\n",
    "#         label = id2Label[_id]\n",
    "#         print(f\"{i - total_window - 1};{label};{out[_id]}\")\n",
    "    \n",
    "#         image = torchvision.io.read_image(f\"/kaggle/input/keycls-test/test_data/raw_frames/{video}/frame_{i}.jpg\")\n",
    "#         window.append(image)\n",
    "#         window = window[1:]\n",
    "    \n",
    "#     i += 1\n",
    "#     if i == len(images):\n",
    "#         recording = False"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5342092,
     "sourceId": 8874695,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 63797,
     "sourceId": 75931,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 182.103034,
   "end_time": "2024-07-10T05:30:13.537111",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-10T05:27:11.434077",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "084ac9d706994fedaf85d8658692f8ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_87c2cabd2c0c4960a8d06c973b69eb80",
       "max": 274.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c9ff3407c8c0449695c8146c94a57580",
       "value": 274.0
      }
     },
     "115f2786f4944656ac6bd442e914beff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d563d21363c646628462ae9f77703109",
       "placeholder": "​",
       "style": "IPY_MODEL_deac082b04954edd9992a3e73fa4ce97",
       "value": " 274/274 [01:49&lt;00:00,  2.50it/s]"
      }
     },
     "33328fa0bf594946afd5eef1b0961f15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e462f4c3ddae4217829d288137391f02",
       "placeholder": "​",
       "style": "IPY_MODEL_9e8617601f424415a652539bebde9fa0",
       "value": " 2/2 [00:01&lt;00:00,  1.59it/s]"
      }
     },
     "42ff4d480db94c7792cc5cd69200e802": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bb6388722ec04ff7ae78a08afca71ef2",
        "IPY_MODEL_084ac9d706994fedaf85d8658692f8ca",
        "IPY_MODEL_115f2786f4944656ac6bd442e914beff"
       ],
       "layout": "IPY_MODEL_ec89fddd4e2948588b453b1199847711"
      }
     },
     "4960a826919344958e8098956facf11d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a18e022320a4f078bd448b7dbcb9d18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "6fe68cac12394592a3785d0af3e9fef7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7755fcadc11142ba9aec15d7a7bf1a63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7f8365f0f1884989a4f2b4809924eb48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ada78a8589244eb2ab4914ff34fed6a9",
        "IPY_MODEL_dd9df287a0ab460893e4c34b3d96e15c",
        "IPY_MODEL_33328fa0bf594946afd5eef1b0961f15"
       ],
       "layout": "IPY_MODEL_4a18e022320a4f078bd448b7dbcb9d18"
      }
     },
     "87968f72ae6d43c1861f01a54da72017": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "87c2cabd2c0c4960a8d06c973b69eb80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e8617601f424415a652539bebde9fa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ada78a8589244eb2ab4914ff34fed6a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4960a826919344958e8098956facf11d",
       "placeholder": "​",
       "style": "IPY_MODEL_87968f72ae6d43c1861f01a54da72017",
       "value": "Sanity Checking DataLoader 0: 100%"
      }
     },
     "bb6388722ec04ff7ae78a08afca71ef2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d5a908f9d96648cf8cba912588e099f4",
       "placeholder": "​",
       "style": "IPY_MODEL_f62c1e08e6a94da28c8f58c35e7b8f96",
       "value": "Testing DataLoader 0: 100%"
      }
     },
     "c9ff3407c8c0449695c8146c94a57580": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d563d21363c646628462ae9f77703109": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5a908f9d96648cf8cba912588e099f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd9df287a0ab460893e4c34b3d96e15c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6fe68cac12394592a3785d0af3e9fef7",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7755fcadc11142ba9aec15d7a7bf1a63",
       "value": 2.0
      }
     },
     "deac082b04954edd9992a3e73fa4ce97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e462f4c3ddae4217829d288137391f02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec89fddd4e2948588b453b1199847711": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "f62c1e08e6a94da28c8f58c35e7b8f96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
