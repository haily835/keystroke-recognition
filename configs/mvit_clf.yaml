fit:
  seed_everything: true
  trainer:
    logger:
      class_path: lightning.pytorch.loggers.CSVLogger
      init_args:
        save_dir: logs
    callbacks:
      - class_path: lightning.pytorch.callbacks.EarlyStopping
        init_args:
          patience: 5
          monitor: val_loss
    fast_dev_run: false
    max_epochs: 100
  model:
    name: mvit_clf
    classpath: pytorchvideo.models.create_multiscale_vision_transformers
    init_args:
      spatial_size: [224, 224]
      temporal_size: 8
      embed_dim_mul: [[1, 2.0], [3, 2.0], [14, 2.0]]
      atten_head_mul: [[1, 2.0], [3, 2.0], [14, 2.0]]
      pool_q_stride_size: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
      pool_kv_stride_adaptive: [1, 8, 8]
      pool_kvq_kernel: [3, 3, 3]
      head_num_classes: len(clf_id2label)
    id2label: clf_id2label
    label2id: clf_label2id
  data:
    delay: 4
    resize_shape: [224, 224]
    train_videos: ['video_0', 'video_1', 'video_2', 'video_3', 'video_4']
    val_videos: ['video_5']
    test_videos: ['video_6', 'video_7']
    idle_gap: null
    train_transforms: [
      'v2.RandomRotation(degrees=10)',
      'v2.RandomAdjustSharpness(sharpness_factor=2)',
      'v2.RandomAdjustSharpness(sharpness_factor=2)',
      'v2.ColorJitter(brightness=(0.5,1.5),contrast=(1),saturation=(0.5,1.5),hue=(-0.1,0.1))',
    ]
    val_transforms: []
    test_transforms: []
  optimizer:
    class_path: torch.optim.Adam
    init_args:
      lr: 0.001
test:
  seed_everything: true
  trainer:
    logger:
      class_path: lightning.pytorch.loggers.CSVLogger
      init_args:
        save_dir: logs
    fast_dev_run: false
  model:
    name: mvit_clf
    classpath: pytorchvideo.models.create_multiscale_vision_transformers
    init_args:
      spatial_size: 224
      temporal_size: 8
      embed_dim_mul: [[1, 2.0], [3, 2.0], [14, 2.0]]
      atten_head_mul: [[1, 2.0], [3, 2.0], [14, 2.0]]
      pool_q_stride_size: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
      pool_kv_stride_adaptive: [1, 8, 8]
      pool_kvq_kernel: [3, 3, 3]
      head_num_classes: len(clf_id2label)
    id2label: clf_id2label
    label2id: clf_label2id
  data:
    delay: 4
    resize_shape: [224, 224]
    train_videos: []
    val_videos: []
    test_videos: ['video_6', 'video_7']
    idle_gap: null
    train_transforms: [
      'v2.RandomRotation(degrees=10)',
      'v2.RandomAdjustSharpness(sharpness_factor=2)',
      'v2.RandomAdjustSharpness(sharpness_factor=2)',
      'v2.ColorJitter(brightness=(0.5,1.5),contrast=(1),saturation=(0.5,1.5),hue=(-0.1,0.1))',
    ]
    val_transforms: []
    test_transforms: []