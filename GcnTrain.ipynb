{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning torchvision mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  ['BackSpace', 'a', 'b', 'c', 'comma', 'd', 'dot', 'e', 'f', 'g', 'h', 'i']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = './datasets/angle/segments_landmarks'\n",
    "\n",
    "id2label = ['comma', 'dot', 'BackSpace', 'idle', 'space', \n",
    "            'a', 'b', 'c', 'd', 'e', 'f', \n",
    "            'g', 'h', 'i', 'j', 'k', 'l', \n",
    "            'm', 'n', 'o', 'p', 'q', 'r', \n",
    "            's', 't', 'u', 'v', 'w', 'x', \n",
    "            'y', 'z']\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(id2label)}\n",
    "\n",
    "class_paths = sorted(glob.glob(f\"{data_dir}/*.pt\"))\n",
    "\n",
    "classes = [class_path.split('/')[-1].split('.')[0] for class_path in class_paths]\n",
    "print('classes: ', classes)\n",
    "\n",
    "labels = []\n",
    "all_samples = []\n",
    "for class_path in class_paths:\n",
    "    label = class_path.split('/')[-1].split('.')[0]\n",
    "    samples = torch.load(class_path)\n",
    "    for sample in samples:\n",
    "        labels.append(label2id[label])\n",
    "        all_samples.append(sample)\n",
    "\n",
    "fit, test, fit_label, test_label = train_test_split(all_samples, labels, test_size=0.2, random_state=0)\n",
    "train, val, train_label, val_label = train_test_split(fit, fit_label, test_size=0.25, random_state=0)\n",
    "\n",
    "test = torch.stack(test)\n",
    "test_label = torch.stack(test_label)\n",
    "train = torch.stack(train)\n",
    "train_label = torch.stack(train_label)\n",
    "val = torch.stack(val)\n",
    "val_label = torch.stack(val_label)\n",
    "\n",
    "torch.save(test, './datasets/angle/mp/test.pt')\n",
    "torch.save(test_label, './datasets/angle/mp/test_label.pt')\n",
    "\n",
    "torch.save(train, './datasets/angle/mp/train.pt')\n",
    "torch.save(train_label, './datasets/angle/mp/train_label.pt')\n",
    "\n",
    "torch.save(val, './datasets/angle/mp/val.pt')\n",
    "torch.save(val_label, './datasets/angle/mp/val_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/haily/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      " Counter({'idle': 2715, 'space': 917, 'e': 497, 'BackSpace': 429, 'i': 328, 'a': 320, 'o': 302, 't': 289, 'r': 250, 'n': 246, 's': 215, 'u': 184, 'l': 183, 'h': 162, 'd': 159, 'c': 155, 'y': 119, 'g': 109, 'm': 109, 'p': 108, 'w': 103, 'b': 91, 'k': 86, 'f': 85, 'dot': 84, 'v': 73, 'comma': 66, 'j': 62, 'z': 58, 'x': 54, 'q': 52})\n",
      "Val:\n",
      " Counter({'idle': 973, 'space': 311, 'e': 162, 'BackSpace': 136, 'i': 112, 'a': 108, 't': 96, 'o': 87, 'n': 75, 'r': 73, 'h': 67, 's': 62, 'u': 57, 'l': 52, 'c': 49, 'd': 49, 'f': 43, 'y': 41, 'm': 39, 'g': 38, 'w': 28, 'p': 26, 'comma': 26, 'b': 26, 'z': 24, 'dot': 23, 'v': 22, 'x': 18, 'k': 16, 'j': 16, 'q': 15})\n",
      "Test:\n",
      " Counter({'idle': 944, 'space': 316, 'BackSpace': 164, 'e': 147, 'i': 112, 't': 103, 'o': 94, 'n': 85, 'r': 84, 'a': 80, 's': 64, 'l': 62, 'c': 57, 'u': 54, 'm': 53, 'd': 46, 'h': 42, 'w': 37, 'f': 36, 'y': 36, 'g': 33, 'p': 31, 'b': 31, 'dot': 28, 'k': 23, 'v': 23, 'q': 21, 'comma': 20, 'x': 20, 'z': 13, 'j': 11})\n",
      "train_weights: \n",
      " [4.2082111436950145, 3.306451612903226, 0.6474170990300022, 0.10229905542684013, 0.3028810637773947, 0.8679435483870968, 3.0521091811414394, 1.7918834547346514, 1.7468046256847232, 0.558836892321672, 3.267552182163188, 2.548091151228174, 1.7144563918757467, 0.8467741935483871, 4.479708636836628, 3.229557389347337, 1.5177154944473823, 2.548091151228174, 1.1290322580645162, 0.9196752830591753, 2.57168458781362, 5.341191066997519, 1.110967741935484, 1.2918229557389347, 0.9610447594597611, 1.5094670406732118, 3.8046840477242596, 2.696523645474475, 5.14336917562724, 2.333965844402277, 4.788654060066741]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haily/Documents/GitHub/Research Learning/resnet.py:130: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from key_utils import KeySegmentDataModule, KeyClf, id2label\n",
    "    from models.resnet import resnet101\n",
    "except:\n",
    "    import sys\n",
    "    sys.path.append(\"/kaggle/input/keystroke-util\")\n",
    "    from key_utils import KeySegmentDataModule, KeyClf, id2label\n",
    "    from models.resnet import resnet101\n",
    "\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "import torchvision\n",
    "import torchvision.transforms.functional\n",
    "import lightning as L\n",
    "\n",
    "\n",
    "\n",
    "dm = KeySegmentDataModule(segment_dir='datasets/angle/segments_dir', \n",
    "                          num_workers=0,\n",
    "                          transforms=transforms)\n",
    "weights = dm.train_weights\n",
    "\n",
    "class ResnetKeyClf(KeyClf):\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        super().__init__(weights, learning_rate)\n",
    "        self.model = resnet101(sample_size=224, sample_duration=8, num_classes=len(id2label))\n",
    "\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator='cpu',\n",
    "    devices='auto',\n",
    "    fast_dev_run=True,\n",
    "    log_every_n_steps=100,\n",
    "    callbacks=EarlyStopping(monitor='val_loss', patience=5),\n",
    "    max_epochs=100,\n",
    ")\n",
    "\n",
    "model = ResnetKeyClf()\n",
    "\n",
    "# trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpg_files:  ['datasets/angle/segments_dir/idle/video_6_idle_f4901_4908/frame_4901.jpg', 'datasets/angle/segments_dir/idle/video_6_idle_f4901_4908/frame_4902.jpg', 'datasets/angle/segments_dir/idle/video_6_idle_f4901_4908/frame_4903.jpg', 'datasets/angle/segments_dir/idle/video_6_idle_f4901_4908/frame_4904.jpg', 'datasets/angle/segments_dir/idle/video_6_idle_f4901_4908/frame_4905.jpg', 'datasets/angle/segments_dir/idle/video_6_idle_f4901_4908/frame_4906.jpg', 'datasets/angle/segments_dir/idle/video_6_idle_f4901_4908/frame_4907.jpg', 'datasets/angle/segments_dir/idle/video_6_idle_f4901_4908/frame_4908.jpg']\n"
     ]
    }
   ],
   "source": [
    "frames, label = dm.train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3, 8, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(label)\n",
    "print(frames.shape)\n",
    "torchvision.io.video.write_video('test.mp4', frames.permute(1, 2, 3, 0) * 255, fps=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 70015), started 0:00:32 ago. (Use '!kill 70015' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a1bc3ea66a05900d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a1bc3ea66a05900d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
